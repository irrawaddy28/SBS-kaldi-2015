nohup: ignoring input
Number of languages = 11
lang = cantonese, conf = conf/lang/101-cantonese-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/101-cantonese/release-current/conversational/training /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Cantonese_Babel101/train.LimitedLP.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/101-cantonese/release-current/conversational/training according to train.LimitedLP.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/101-cantonese/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Cantonese_Babel101/dev.3hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/101-cantonese/release-current/conversational/dev according to dev.3hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/101-cantonese/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Cantonese_Babel101/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/101-cantonese/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Wed Jul 1 01:43:14 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/101-cantonese/release-babel101b-v0.4c_sub-train1/conversational/reference_materials/lexicon.sub-train1.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
	Romanized forms of words expected in the dictionary
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ;
local/prepare_lexicon.pl: Read 5087 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 5981 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 37 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 6 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 7 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Wed Jul 1 01:43:15 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 865 |' 'echo 5092 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 8 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 844 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 38 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 38 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 16 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 864 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 8 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 76 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Wed Jul 1 01:43:16 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 5091 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 120 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 10221 non-empty utterances from 120 files
local/prepare_acoustic_training_data.pl: Found 120 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 120 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 10221 lines each to text, utt2spk and segments
	Wrote 120 lines to wav.scp
	Wrote 120 lines to spk2utt
	Total # words = 101794 (including 1768 OOVs) + 12366 <silence>
	Amount of speech = 17.88 hours (including some due to <silence>)
	Average utterance length = 6.30 sec +/- 1.84 sec, and 9.96 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Wed Jul 1 01:43:17 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 20 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 1658 non-empty utterances from 20 files
local/prepare_acoustic_training_data.pl: Found 20 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 20 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 1658 lines each to text, utt2spk and segments
	Wrote 20 lines to wav.scp
	Wrote 20 lines to spk2utt
	Amount of speech = 2.94 hours (including some due to <silence>)
	Average utterance length = 6.39 sec +/- 1.98 sec, and 10.34 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Wed Jul 1 01:43:17 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_BP_101_10713_20111024_220917_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 6.650), segments file: (6.65 13.21)
Warning: BABEL_BP_101_10713_20111024_220917_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 7.280), segments file: (7.28 15.23)
Warning: BABEL_BP_101_10733_20111021_141006_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 5.690), segments file: (5.69 9.71)
Warning: BABEL_BP_101_10733_20111021_141006_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (5.690, 9.710), segments file: (5.69 9.71)
Warning: BABEL_BP_101_10733_20111021_141006_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.650, 7.750), segments file: (7.75 10.75)
Warning: BABEL_BP_101_10733_20111021_141006_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.650, 7.750), segments file: (7.75 10.75)
Warning: BABEL_BP_101_20741_20111018_195422_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 5.130), segments file: (11.16 19.37)
Warning: BABEL_BP_101_20741_20111018_195422_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (5.130, 11.160), segments file: (11.16 19.37)
Warning: BABEL_BP_101_20741_20111018_195422_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 6.710), segments file: (13.0 16.88)
Warning: BABEL_BP_101_20741_20111018_195422_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (6.710, 13.000), segments file: (13.0 16.88)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Wed Jul 1 01:43:17 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 5093 lines, 5093 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 122750 words, 10221 sentences
train.txt contains 112529 words, 10221 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 20233 words, 1658 sentences
data/srilm/dev.txt contains 18575 words, 1658 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40373.3  ppl=  98.951   ppl1=  149.118
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40428.3  ppl=  99.5723  ppl1=  150.138
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40431.5  ppl=  99.6078  ppl1=  150.197
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40432.8  ppl=  99.6227  ppl1=  150.221
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40441.5  ppl=  99.7214  ppl1=  150.383
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40460.1  ppl=  99.9334  ppl1=  150.732
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40495.2  ppl=  100.333  ppl1=  151.388
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40510.6  ppl=  100.509  ppl1=  151.678
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40543.9  ppl=  100.89   ppl1=  152.304
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40547    ppl=  100.926  ppl1=  152.363
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40575.7  ppl=  101.256  ppl1=  152.905
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40669.8  ppl=  102.347  ppl1=  154.701
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40721.5  ppl=  102.95   ppl1=  155.694
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40736.3  ppl=  103.124  ppl1=  155.98
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40969    ppl=  105.891  ppl1=  160.545
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -40972.1  ppl=  105.929  ppl1=  160.608
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -41000.8  ppl=  106.275  ppl1=  161.18
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -41121.7  ppl=  107.747  ppl1=  163.613
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -41251    ppl=  109.345  ppl1=  166.258
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -41254.9  ppl=  109.394  ppl1=  166.339
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -41262.1  ppl=  109.482  ppl1=  166.485
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  1658  sentences,  18575  words,  0  OOVs  0  zeroprobs,  logprob=  -41512.2  ppl=  112.644  ppl1=  171.729
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Wed Jul 1 01:43:25 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -1.53705
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Wed Jul 1 01:43:26 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept all 10221 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 10221 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Wed Jul 1 01:45:31 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 10221 to 5000
utils/subset_data_dir.sh: reducing #utt from 10221 to 10000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Wed Jul 1 01:45:31 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
65 warnings in exp/mono/log/update.*.log
743 warnings in exp/mono/log/acc.*.*.log
15301 warnings in exp/mono/log/align.*.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Wed Jul 1 02:00:34 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
33 warnings in exp/tri1/log/update.*.log
1 warnings in exp/tri1/log/compile_questions.log
1 warnings in exp/tri1/log/build_tree.log
195 warnings in exp/tri1/log/acc.*.*.log
1445 warnings in exp/tri1/log/align.*.*.log
3 warnings in exp/tri1/log/init_model.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Wed Jul 1 02:11:23 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
71 warnings in exp/tri2/log/init_model.log
1 warnings in exp/tri2/log/compile_questions.log
138 warnings in exp/tri2/log/update.*.log
1125 warnings in exp/tri2/log/align.*.*.log
1 warnings in exp/tri2/log/build_tree.log
229 warnings in exp/tri2/log/acc.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Wed Jul 1 02:37:41 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri3/log/build_tree.log
50 warnings in exp/tri3/log/init_model.log
1051 warnings in exp/tri3/log/align.*.*.log
1 warnings in exp/tri3/log/compile_questions.log
129 warnings in exp/tri3/log/update.*.log
238 warnings in exp/tri3/log/acc.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Wed Jul 1 02:58:40 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
79 warnings in exp/tri4/log/init_model.log
163 warnings in exp/tri4/log/acc.*.*.log
837 warnings in exp/tri4/log/align.*.*.log
1 warnings in exp/tri4/log/compile_questions.log
1 warnings in exp/tri4/log/build_tree.log
7 warnings in exp/tri4/log/lda_acc.*.log
86 warnings in exp/tri4/log/update.*.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Wed Jul 1 03:11:13 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
22 warnings in exp/tri5/log/fmllr.*.*.log
37 warnings in exp/tri5/log/init_model.log
186 warnings in exp/tri5/log/acc.*.*.log
1 warnings in exp/tri5/log/build_tree.log
65 warnings in exp/tri5/log/update.*.log
733 warnings in exp/tri5/log/align.*.*.log
1 warnings in exp/tri5/log/est_alimdl.log
1 warnings in exp/tri5/log/compile_questions.log
steps/train_sat.sh: Likelihood evolution:
-44.4435 -46.3465 -45.3829 -45.3171 -44.2653 -43.4586 -42.9745 -42.6016 -42.2998 -41.8066 -41.5704 -41.0096 -40.8026 -40.668 -40.5531 -40.4445 -40.3381 -40.2383 -40.1458 -39.9792 -39.8477 -39.7607 -39.6854 -39.614 -39.5432 -39.4736 -39.4063 -39.3415 -39.277 -39.1791 -39.103 -39.0636 -39.0338 -39.0106 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Wed Jul 1 03:24:23 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
159 warnings in exp/tri5_ali/log/align_pass2.*.log
178 warnings in exp/tri5_ali/log/align_pass1.*.log
5 warnings in exp/tri5_ali/log/fmllr.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/101-cantonese/release-current/conversational/dev
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Cantonese_Babel101/dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/101-cantonese/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Cantonese_Babel101/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/101-cantonese/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Wed Jul 1 03:27:11 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Cantonese_Babel101/uem/db-v8-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel101b-v0.4c_conv-dev/IARPA-babel101b-v0.4c_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Wed Jul 1 03:27:11 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Cantonese_Babel101/uem/db-v8-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-v8-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 220 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 120 files
filelist filelist.list contains 120 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Wed Jul 1 03:27:12 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_BP_101_10470_20111118_172644_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 5.150), segments file: (4.87 6.71)
Warning: BABEL_BP_101_10713_20111024_220917_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 6.650), segments file: (9.95 11.37)
Warning: BABEL_BP_101_10713_20111024_220917_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (597.144, 600.040), segments file: (593.97 596.34)
Warning: BABEL_BP_101_10713_20111024_220917_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 7.280), segments file: (22.68 27.04)
Warning: BABEL_BP_101_10713_20111024_220917_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (11.256, 15.230), segments file: (22.68 27.04)
Warning: BABEL_BP_101_10713_20111024_220917_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (21.014, 22.940), segments file: (22.68 27.04)
Warning: BABEL_BP_101_10713_20111024_220917_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (21.014, 22.940), segments file: (22.68 27.04)
Warning: BABEL_BP_101_10733_20111021_141006_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 5.690), segments file: (5.37 6.56)
Warning: BABEL_BP_101_10733_20111021_141006_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.650, 7.750), segments file: (12.23 13.43)
Warning: BABEL_BP_101_10733_20111021_141006_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.650, 7.750), segments file: (12.23 13.43)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Wed Jul 1 03:27:12 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 9458 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 9458 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Wed Jul 1 03:28:24 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Wed Jul 1 03:28:24 CDT 2015
---------------------------------------------------------------------
fstminimizeencoded 
fstdeterminizestar --use-log=true 
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstisstochastic data/lang/tmp/LG.fst 
0.000482429 -1.65737
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000482429 -1.65737
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstminimizeencoded 
fstdeterminizestar --use-log=true 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstrmepslocal 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.000827238 -1.65762
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Wed Jul 1 05:47:50 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Wed Jul 1 05:47:53 CDT 2015
lang = assamese, conf = conf/lang/102-assamese-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/102-assamese/release-current/conversational/training /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Assamese_Babel102/train.LimitedLP.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/102-assamese/release-current/conversational/training according to train.LimitedLP.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/102-assamese/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Assamese_Babel102/dev.2hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/102-assamese/release-current/conversational/dev according to dev.2hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/102-assamese/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Assamese_Babel102//dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/102-assamese/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Wed Jul 1 05:47:54 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/102-assamese/release-current/conversational/reference_materials/lexicon.sub-train.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
	Romanized forms of words expected in the dictionary
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ;
local/prepare_lexicon.pl: Read 7661 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 8271 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 50 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 0 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 2 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Wed Jul 1 05:47:55 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 221 |' 'echo 7666 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 5 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 200 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 51 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 51 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 11 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 220 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 14 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 23 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Wed Jul 1 05:47:57 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 7665 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 138 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 10997 non-empty utterances from 138 files
local/prepare_acoustic_training_data.pl: Found 138 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 138 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 10997 lines each to text, utt2spk and segments
	Wrote 138 lines to wav.scp
	Wrote 120 lines to spk2utt
	Total # words = 76351 (including 2362 OOVs) + 14994 <silence>
	Amount of speech = 10.03 hours (including some due to <silence>)
	Average utterance length = 3.28 sec +/- 2.95 sec, and 6.94 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Wed Jul 1 05:47:59 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 24 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 2026 non-empty utterances from 24 files
local/prepare_acoustic_training_data.pl: Found 24 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 24 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 2026 lines each to text, utt2spk and segments
	Wrote 24 lines to wav.scp
	Wrote 24 lines to spk2utt
	Amount of speech = 1.96 hours (including some due to <silence>)
	Average utterance length = 3.49 sec +/- 2.91 sec, and 7.25 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Wed Jul 1 05:47:59 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_102_10408_20121105_223454_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.115), segments file: (0.115 4.345)
Warning: BABEL_OP1_102_10408_20121105_223454_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.115, 4.345), segments file: (0.115 4.345)
Warning: BABEL_OP1_102_10408_20121105_223454_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (597.015, 599.660), segments file: (595.735 597.015)
Warning: BABEL_OP1_102_10408_20121105_223454_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.405), segments file: (0.405 1.285)
Warning: BABEL_OP1_102_10408_20121105_223454_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.405, 1.285), segments file: (0.405 1.285)
Warning: BABEL_OP1_102_10408_20121105_223454_outLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (599.835, 599.940), segments file: (598.355 599.835)
Warning: BABEL_OP1_102_10925_20120329_192327_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 1.395), segments file: (1.395 7.615)
Warning: BABEL_OP1_102_10925_20120329_192327_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.395, 7.615), segments file: (1.395 7.615)
Warning: BABEL_OP1_102_10925_20120329_192327_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (595.885, 599.480), segments file: (584.405 595.885)
Warning: BABEL_OP1_102_10925_20120329_192327_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 3.125), segments file: (6.425 6.985)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Wed Jul 1 05:47:59 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 7667 lines, 7667 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 87641 words, 10997 sentences
train.txt contains 76644 words, 10997 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 16667 words, 2026 sentences
data/srilm/dev.txt contains 14641 words, 2026 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.4505
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39366.7  ppl=  230.12   ppl1=  488.426
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39420.5  ppl=  231.838  ppl1=  492.578
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39424.1  ppl=  231.953  ppl1=  492.858
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39434.4  ppl=  232.282  ppl1=  493.652
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39502.3  ppl=  234.471  ppl1=  498.951
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39509.5  ppl=  234.706  ppl1=  499.522
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39513.1  ppl=  234.823  ppl1=  499.806
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39523.4  ppl=  235.156  ppl1=  500.611
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39533    ppl=  235.467  ppl1=  501.366
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39545.4  ppl=  235.873  ppl1=  502.35
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39556    ppl=  236.216  ppl1=  503.182
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39667.9  ppl=  239.896  ppl1=  512.115
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39679.1  ppl=  240.27   ppl1=  513.024
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39689.7  ppl=  240.62   ppl1=  513.874
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39887.3  ppl=  247.282  ppl1=  530.1
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39890.9  ppl=  247.405  ppl1=  530.401
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39901.2  ppl=  247.755  ppl1=  531.256
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -39989.8  ppl=  250.809  ppl1=  538.717
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -40024.1  ppl=  251.999  ppl1=  541.628
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -40100.8  ppl=  254.684  ppl1=  548.203
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -40102.9  ppl=  254.758  ppl1=  548.383
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  2026  sentences,  14641  words,  0  OOVs  0  zeroprobs,  logprob=  -40182    ppl=  257.555  ppl1=  555.243
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Wed Jul 1 05:48:09 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -2.09414
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Wed Jul 1 05:48:09 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept all 10997 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 10997 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Wed Jul 1 05:49:29 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 10997 to 5000
utils/subset_data_dir.sh: reducing #utt from 10997 to 10000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Wed Jul 1 05:49:29 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
507 warnings in exp/mono/log/acc.*.*.log
13511 warnings in exp/mono/log/align.*.*.log
345 warnings in exp/mono/log/update.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Wed Jul 1 05:58:34 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
15 warnings in exp/tri1/log/init_model.log
74 warnings in exp/tri1/log/update.*.log
1 warnings in exp/tri1/log/compile_questions.log
1 warnings in exp/tri1/log/build_tree.log
1949 warnings in exp/tri1/log/align.*.*.log
814 warnings in exp/tri1/log/acc.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Wed Jul 1 06:05:16 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri2/log/build_tree.log
128 warnings in exp/tri2/log/update.*.log
112 warnings in exp/tri2/log/init_model.log
1578 warnings in exp/tri2/log/align.*.*.log
1 warnings in exp/tri2/log/compile_questions.log
849 warnings in exp/tri2/log/acc.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Wed Jul 1 06:26:43 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri3/log/compile_questions.log
886 warnings in exp/tri3/log/acc.*.*.log
1 warnings in exp/tri3/log/build_tree.log
126 warnings in exp/tri3/log/update.*.log
106 warnings in exp/tri3/log/init_model.log
1530 warnings in exp/tri3/log/align.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Wed Jul 1 06:43:15 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
26 warnings in exp/tri4/log/lda_acc.*.log
774 warnings in exp/tri4/log/acc.*.*.log
1 warnings in exp/tri4/log/compile_questions.log
119 warnings in exp/tri4/log/init_model.log
1296 warnings in exp/tri4/log/align.*.*.log
133 warnings in exp/tri4/log/update.*.log
1 warnings in exp/tri4/log/build_tree.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Wed Jul 1 06:50:35 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
1 warnings in exp/tri5/log/compile_questions.log
78 warnings in exp/tri5/log/init_model.log
753 warnings in exp/tri5/log/acc.*.*.log
110 warnings in exp/tri5/log/fmllr.*.*.log
105 warnings in exp/tri5/log/update.*.log
1090 warnings in exp/tri5/log/align.*.*.log
1 warnings in exp/tri5/log/build_tree.log
2 warnings in exp/tri5/log/est_alimdl.log
steps/train_sat.sh: Likelihood evolution:
-54.088 -54.0792 -53.8457 -53.572 -52.7217 -52.0551 -51.5481 -51.149 -50.8263 -50.2935 -50.0351 -49.6921 -49.4957 -49.3544 -49.2296 -49.1118 -48.9986 -48.8922 -48.7925 -48.6014 -48.4554 -48.3663 -48.2839 -48.2071 -48.1343 -48.0622 -47.9897 -47.9185 -47.8497 -47.7448 -47.6593 -47.6256 -47.6033 -47.586 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Wed Jul 1 06:58:46 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
296 warnings in exp/tri5_ali/log/align_pass1.*.log
20 warnings in exp/tri5_ali/log/fmllr.*.log
251 warnings in exp/tri5_ali/log/align_pass2.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/102-assamese/release-current/conversational/dev
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Assamese_Babel102//dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/102-assamese/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Assamese_Babel102//dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/102-assamese/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Wed Jul 1 07:00:34 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Assamese_Babel102/uem/db-dev-jhuseg-v7-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel102b-v0.5a_conv-dev/IARPA-babel102b-v0.5a_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Wed Jul 1 07:00:34 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Assamese_Babel102/uem/db-dev-jhuseg-v7-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-dev-jhuseg-v7-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 0 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 126 files
filelist filelist.list contains 126 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Wed Jul 1 07:00:35 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_102_10408_20121105_223454_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.115), segments file: (1.99 4.26)
Warning: BABEL_OP1_102_10408_20121105_223454_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.115, 4.345), segments file: (1.99 4.26)
Warning: BABEL_OP1_102_10408_20121105_223454_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.405), segments file: (0.00 1.17)
Warning: BABEL_OP1_102_10925_20120329_192327_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 1.395), segments file: (1.11 2.66)
Warning: BABEL_OP1_102_10925_20120329_192327_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (595.885, 599.480), segments file: (595.44 595.86)
Warning: BABEL_OP1_102_10925_20120329_192327_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 3.125), segments file: (6.49 6.87)
Warning: BABEL_OP1_102_10925_20120329_192327_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (3.125, 3.495), segments file: (6.49 6.87)
Warning: BABEL_OP1_102_10925_20120329_192327_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (3.495, 6.425), segments file: (6.49 6.87)
Warning: BABEL_OP1_102_10925_20120329_192327_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (6.425, 6.985), segments file: (6.49 6.87)
Warning: BABEL_OP1_102_13450_20120421_200138_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 6.725), segments file: (4.91 5.07)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Wed Jul 1 07:00:35 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 13339 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 13339 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Wed Jul 1 07:01:38 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Wed Jul 1 07:01:38 CDT 2015
---------------------------------------------------------------------
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
fstminimizeencoded 
fstdeterminizestar --use-log=true 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstisstochastic data/lang/tmp/LG.fst 
0.000481697 -2.14327
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000481697 -2.14327
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fstminimizeencoded 
fstdeterminizestar --use-log=true 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstrmepslocal 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.693572 -2.14328
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Wed Jul 1 09:08:10 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Wed Jul 1 09:08:15 CDT 2015
lang = bengali, conf = conf/lang/103-bengali-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/103-bengali//release-current/conversational/training /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Bengali_Babel103/train.LimitedLP.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/103-bengali//release-current/conversational/training according to train.LimitedLP.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/103-bengali/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Bengali_Babel103/dev.2hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/103-bengali/release-current/conversational/dev according to dev.2hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/103-bengali/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Bengali_Babel103/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/103-bengali/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Wed Jul 1 09:08:15 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/103-bengali/release-current/conversational/reference_materials/lexicon.sub-train.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
	Romanized forms of words expected in the dictionary
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ;
local/prepare_lexicon.pl: Read 7933 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 9182 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 53 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 0 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 2 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Wed Jul 1 09:08:16 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 233 |' 'echo 7938 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 4 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 212 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 54 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 54 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 11 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 232 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 46 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 2 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Wed Jul 1 09:08:19 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 7937 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 124 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 10221 non-empty utterances from 124 files
local/prepare_acoustic_training_data.pl: Found 124 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 124 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 10221 lines each to text, utt2spk and segments
	Wrote 124 lines to wav.scp
	Wrote 120 lines to spk2utt
	Total # words = 78253 (including 2513 OOVs) + 14052 <silence>
	Amount of speech = 10.33 hours (including some due to <silence>)
	Average utterance length = 3.64 sec +/- 3.64 sec, and 7.66 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Wed Jul 1 09:08:20 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 12 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 873 non-empty utterances from 12 files
local/prepare_acoustic_training_data.pl: Found 12 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 12 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 873 lines each to text, utt2spk and segments
	Wrote 12 lines to wav.scp
	Wrote 12 lines to spk2utt
	Amount of speech = 1.04 hours (including some due to <silence>)
	Average utterance length = 4.27 sec +/- 4.41 sec, and 9.22 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Wed Jul 1 09:08:20 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_103_10569_20111221_201913_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.915), segments file: (2.915 3.455)
Warning: BABEL_OP1_103_10569_20111221_201913_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.915, 3.455), segments file: (2.915 3.455)
Warning: BABEL_OP1_103_10569_20111221_201913_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (592.665, 599.020), segments file: (592.355 592.665)
Warning: BABEL_OP1_103_10569_20111221_201913_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 4.655), segments file: (4.655 5.205)
Warning: BABEL_OP1_103_10569_20111221_201913_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.655, 5.205), segments file: (4.655 5.205)
Warning: BABEL_OP1_103_10569_20111221_201913_outLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (599.715, 599.820), segments file: (597.025 599.715)
Warning: BABEL_OP1_103_10576_20111221_214850_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.275), segments file: (3.735 17.755)
Warning: BABEL_OP1_103_10576_20111221_214850_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.275, 0.945), segments file: (3.735 17.755)
Warning: BABEL_OP1_103_10576_20111221_214850_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.945, 3.735), segments file: (3.735 17.755)
Warning: BABEL_OP1_103_10576_20111221_214850_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (3.735, 17.755), segments file: (3.735 17.755)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Wed Jul 1 09:08:20 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 7939 lines, 7939 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 89242 words, 10221 sentences
train.txt contains 79021 words, 10221 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 9007 words, 873 sentences
data/srilm/dev.txt contains 8134 words, 873 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22015.3  ppl=  278.127  ppl1=  508.834
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22019.3  ppl=  278.412  ppl1=  509.413
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22024    ppl=  278.747  ppl1=  510.092
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22027.6  ppl=  279.004  ppl1=  510.611
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22071.6  ppl=  282.161  ppl1=  517.015
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22075.6  ppl=  282.445  ppl1=  517.59
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22076.4  ppl=  282.503  ppl1=  517.707
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22076.5  ppl=  282.516  ppl1=  517.733
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22153.8  ppl=  288.152  ppl1=  529.182
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22158.5  ppl=  288.498  ppl1=  529.888
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22162.1  ppl=  288.763  ppl1=  530.427
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22214.6  ppl=  292.668  ppl1=  538.376
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22218.6  ppl=  292.965  ppl1=  538.979
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22219.6  ppl=  293.037  ppl1=  539.127
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22329.3  ppl=  301.374  ppl1=  556.137
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22334    ppl=  301.737  ppl1=  556.879
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22337.6  ppl=  302.014  ppl1=  557.445
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22380.3  ppl=  305.329  ppl1=  564.224
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22388.2  ppl=  305.948  ppl1=  565.491
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22412.6  ppl=  307.858  ppl1=  569.4
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22416.9  ppl=  308.198  ppl1=  570.098
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  873  sentences,  8134  words,  0  OOVs  0  zeroprobs,  logprob=  -22455.2  ppl=  311.228  ppl1=  576.307
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Wed Jul 1 09:08:30 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -4.52439
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Wed Jul 1 09:08:31 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept all 10221 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 10221 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Wed Jul 1 09:09:51 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 10221 to 5000
utils/subset_data_dir.sh: reducing #utt from 10221 to 10000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Wed Jul 1 09:09:51 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
14303 warnings in exp/mono/log/align.*.*.log
528 warnings in exp/mono/log/update.*.log
736 warnings in exp/mono/log/acc.*.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Wed Jul 1 09:19:51 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri1/log/compile_questions.log
44 warnings in exp/tri1/log/update.*.log
9 warnings in exp/tri1/log/init_model.log
2157 warnings in exp/tri1/log/align.*.*.log
668 warnings in exp/tri1/log/acc.*.*.log
1 warnings in exp/tri1/log/build_tree.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Wed Jul 1 09:27:06 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
141 warnings in exp/tri2/log/update.*.log
1 warnings in exp/tri2/log/build_tree.log
839 warnings in exp/tri2/log/acc.*.*.log
1749 warnings in exp/tri2/log/align.*.*.log
102 warnings in exp/tri2/log/init_model.log
1 warnings in exp/tri2/log/compile_questions.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Wed Jul 1 09:48:21 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
88 warnings in exp/tri3/log/update.*.log
1 warnings in exp/tri3/log/build_tree.log
859 warnings in exp/tri3/log/acc.*.*.log
1695 warnings in exp/tri3/log/align.*.*.log
83 warnings in exp/tri3/log/init_model.log
1 warnings in exp/tri3/log/compile_questions.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Wed Jul 1 10:04:41 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
1 warnings in exp/tri4/log/compile_questions.log
1 warnings in exp/tri4/log/build_tree.log
1394 warnings in exp/tri4/log/align.*.*.log
25 warnings in exp/tri4/log/lda_acc.*.log
125 warnings in exp/tri4/log/update.*.log
825 warnings in exp/tri4/log/acc.*.*.log
78 warnings in exp/tri4/log/init_model.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Wed Jul 1 10:12:13 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 57 with no stats; corresponding phone list: 229 230 231 232 
This is a bad warning.
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
117 warnings in exp/tri5/log/fmllr.*.*.log
741 warnings in exp/tri5/log/acc.*.*.log
1 warnings in exp/tri5/log/questions.log
137 warnings in exp/tri5/log/update.*.log
4 warnings in exp/tri5/log/est_alimdl.log
1 warnings in exp/tri5/log/build_tree.log
1265 warnings in exp/tri5/log/align.*.*.log
1 warnings in exp/tri5/log/compile_questions.log
50 warnings in exp/tri5/log/init_model.log
steps/train_sat.sh: Likelihood evolution:
-52.91 -52.7495 -52.6032 -52.3919 -51.2704 -50.437 -49.9733 -49.5925 -49.289 -48.7934 -48.5582 -48.2116 -48.0307 -47.8929 -47.7708 -47.6575 -47.5495 -47.4481 -47.35 -47.177 -47.0389 -46.9512 -46.8691 -46.7917 -46.7179 -46.6475 -46.5782 -46.5081 -46.4411 -46.3402 -46.2611 -46.2295 -46.2079 -46.1921 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Wed Jul 1 10:20:41 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
20 warnings in exp/tri5_ali/log/fmllr.*.log
318 warnings in exp/tri5_ali/log/align_pass2.*.log
327 warnings in exp/tri5_ali/log/align_pass1.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/103-bengali/release-current/conversational/dev
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Bengali_Babel103/dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/103-bengali/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Bengali_Babel103/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/103-bengali/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Wed Jul 1 10:22:34 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Bengali_Babel103/uem/db-dev-jhuseg-v7-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel103b-v0.4b_conv-dev/IARPA-babel103b-v0.4b_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Wed Jul 1 10:22:34 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Bengali_Babel103/uem/db-dev-jhuseg-v7-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-dev-jhuseg-v7-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 0 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 125 files
filelist filelist.list contains 125 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Wed Jul 1 10:22:35 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_103_10569_20111221_201913_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.915), segments file: (2.98 3.50)
Warning: BABEL_OP1_103_10569_20111221_201913_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.915, 3.455), segments file: (2.98 3.50)
Warning: BABEL_OP1_103_10569_20111221_201913_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 4.655), segments file: (4.70 5.06)
Warning: BABEL_OP1_103_10569_20111221_201913_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.655, 5.205), segments file: (4.70 5.06)
Warning: BABEL_OP1_103_10576_20111221_214850_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.275), segments file: (3.80 4.89)
Warning: BABEL_OP1_103_10576_20111221_214850_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.275, 0.945), segments file: (3.80 4.89)
Warning: BABEL_OP1_103_10576_20111221_214850_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.945, 3.735), segments file: (3.80 4.89)
Warning: BABEL_OP1_103_10576_20111221_214850_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (3.735, 17.755), segments file: (3.80 4.89)
Warning: BABEL_OP1_103_10576_20111221_214850_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 3.025), segments file: (3.09 3.59)
Warning: BABEL_OP1_103_10576_20111221_214850_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (3.025, 3.515), segments file: (3.09 3.59)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Wed Jul 1 10:22:35 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 12874 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 12874 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Wed Jul 1 10:23:46 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Wed Jul 1 10:23:46 CDT 2015
---------------------------------------------------------------------
fstminimizeencoded 
fstdeterminizestar --use-log=true 
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstisstochastic data/lang/tmp/LG.fst 
0.000481507 -4.52418
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000481507 -4.52418
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstdeterminizestar --use-log=true 
fstminimizeencoded 
fstrmepslocal 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.000815272 -4.52442
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Wed Jul 1 12:32:28 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Wed Jul 1 12:32:34 CDT 2015
lang = pashto, conf = conf/lang/104-pashto-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/104-pashto/release-current/conversational/training /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Pashto_Babel104/train.LimitedLP.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/104-pashto/release-current/conversational/training according to train.LimitedLP.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/104-pashto/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Pashto_Babel104/dev2hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/104-pashto/release-current/conversational/dev according to dev2hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/104-pashto/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Pashto_Babel104/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/104-pashto/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Wed Jul 1 12:32:35 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/104-pashto/release-current-subtrain/conversational/reference_materials/lexicon.sub-train.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
	Romanized forms of words expected in the dictionary
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ;
local/prepare_lexicon.pl: Read 6186 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 8224 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 44 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 2 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 4 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Wed Jul 1 12:32:35 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 489 |' 'echo 6191 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 8 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 468 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 45 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 45 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 13 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 488 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 70 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 53 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Wed Jul 1 12:32:38 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 6190 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 131 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 8786 non-empty utterances from 131 files
local/prepare_acoustic_training_data.pl: Found 131 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 131 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 8786 lines each to text, utt2spk and segments
	Wrote 131 lines to wav.scp
	Wrote 121 lines to spk2utt
	Total # words = 112486 (including 922 OOVs) + 14488 <silence>
	Amount of speech = 9.91 hours (including some due to <silence>)
	Average utterance length = 4.06 sec +/- 3.62 sec, and 12.80 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Wed Jul 1 12:32:39 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 33 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 2060 non-empty utterances from 33 files
local/prepare_acoustic_training_data.pl: Found 33 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 33 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 2060 lines each to text, utt2spk and segments
	Wrote 33 lines to wav.scp
	Wrote 26 lines to spk2utt
	Amount of speech = 2.03 hours (including some due to <silence>)
	Average utterance length = 3.55 sec +/- 3.43 sec, and 10.95 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Wed Jul 1 12:32:39 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_BP_104_04221_20120310_194031_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.105), segments file: (0.105 2.075)
Warning: BABEL_BP_104_04221_20120310_194031_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (599.825, 600.040), segments file: (593.675 599.825)
Warning: BABEL_BP_104_04221_20120310_194031_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.695), segments file: (2.695 3.735)
Warning: BABEL_BP_104_04221_20120310_194031_outLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (595.945, 600.280), segments file: (593.975 595.945)
Warning: BABEL_BP_104_08861_20120226_050237_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.175), segments file: (2.175 3.985)
Warning: BABEL_BP_104_08861_20120226_050237_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 1.545), segments file: (1.545 2.185)
Warning: BABEL_BP_104_08861_20120226_050237_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.545, 2.185), segments file: (1.545 2.185)
Warning: BABEL_BP_104_08861_20120226_050237_outLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (590.655, 600.200), segments file: (587.385 590.655)
Warning: BABEL_BP_104_10712_20120205_004135_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 3.725), segments file: (3.725 6.545)
Warning: BABEL_BP_104_10712_20120205_004135_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 1.455), segments file: (1.455 2.955)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Wed Jul 1 12:32:40 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 6192 lines, 6192 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 122918 words, 8786 sentences
train.txt contains 114132 words, 8786 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 24858 words, 2060 sentences
data/srilm/dev.txt contains 22798 words, 2060 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
warning: discount coeff 7 is out of range: 1.04355
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
warning: discount coeff 7 is out of range: 1.04355
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
warning: discount coeff 7 is out of range: 1.04355
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
warning: discount coeff 7 is out of range: 1.04355
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
warning: discount coeff 7 is out of range: 1.04355
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
warning: discount coeff 7 is out of range: 1.04355
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.10746
warning: discount coeff 7 is out of range: 1.04355
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54047.7  ppl=  149.368  ppl1=  234.813
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54063.9  ppl=  149.593  ppl1=  235.198
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54082.1  ppl=  149.845  ppl1=  235.631
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54082.9  ppl=  149.856  ppl1=  235.65
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54085.1  ppl=  149.887  ppl1=  235.701
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54098.4  ppl=  150.071  ppl1=  236.017
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54119.5  ppl=  150.365  ppl1=  236.522
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54124.5  ppl=  150.434  ppl1=  236.64
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54188.5  ppl=  151.329  ppl1=  238.176
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54211.1  ppl=  151.646  ppl1=  238.72
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54215.4  ppl=  151.706  ppl1=  238.823
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54229.7  ppl=  151.908  ppl1=  239.169
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54314.9  ppl=  153.112  ppl1=  241.236
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54318.9  ppl=  153.169  ppl1=  241.334
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54591.2  ppl=  157.081  ppl1=  248.064
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54607.5  ppl=  157.317  ppl1=  248.47
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54628.6  ppl=  157.626  ppl1=  249.002
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54756.6  ppl=  159.505  ppl1=  252.241
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54901.7  ppl=  161.663  ppl1=  255.964
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54901.8  ppl=  161.666  ppl1=  255.968
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -54926    ppl=  162.028  ppl1=  256.593
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  2060  sentences,  22798  words,  0  OOVs  0  zeroprobs,  logprob=  -55156    ppl=  165.517  ppl1=  262.623
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Wed Jul 1 12:32:50 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -2.0578
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Wed Jul 1 12:32:52 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept all 8786 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 8786 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Wed Jul 1 12:34:15 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 8786 to 5000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Wed Jul 1 12:34:15 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
22578 warnings in exp/mono/log/align.*.*.log
2483 warnings in exp/mono/log/acc.*.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Wed Jul 1 12:49:46 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri1/log/build_tree.log
2722 warnings in exp/tri1/log/acc.*.*.log
3699 warnings in exp/tri1/log/align.*.*.log
1 warnings in exp/tri1/log/compile_questions.log
2 warnings in exp/tri1/log/update.*.log
3 warnings in exp/tri1/log/init_model.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Wed Jul 1 12:58:37 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
2848 warnings in exp/tri2/log/align.*.*.log
1 warnings in exp/tri2/log/compile_questions.log
59 warnings in exp/tri2/log/init_model.log
2483 warnings in exp/tri2/log/acc.*.*.log
1 warnings in exp/tri2/log/build_tree.log
89 warnings in exp/tri2/log/update.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Wed Jul 1 13:21:01 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri3/log/compile_questions.log
2703 warnings in exp/tri3/log/align.*.*.log
70 warnings in exp/tri3/log/update.*.log
1 warnings in exp/tri3/log/build_tree.log
59 warnings in exp/tri3/log/init_model.log
2424 warnings in exp/tri3/log/acc.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Wed Jul 1 13:39:00 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
1 warnings in exp/tri4/log/build_tree.log
59 warnings in exp/tri4/log/init_model.log
103 warnings in exp/tri4/log/update.*.log
1 warnings in exp/tri4/log/compile_questions.log
71 warnings in exp/tri4/log/lda_acc.*.log
2409 warnings in exp/tri4/log/align.*.*.log
2084 warnings in exp/tri4/log/acc.*.*.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Wed Jul 1 13:47:14 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
274 warnings in exp/tri5/log/fmllr.*.*.log
29 warnings in exp/tri5/log/init_model.log
2278 warnings in exp/tri5/log/align.*.*.log
1 warnings in exp/tri5/log/compile_questions.log
1 warnings in exp/tri5/log/build_tree.log
34 warnings in exp/tri5/log/update.*.log
1805 warnings in exp/tri5/log/acc.*.*.log
steps/train_sat.sh: Likelihood evolution:
-54.2893 -53.9646 -53.8343 -53.6038 -52.8662 -52.1553 -51.6508 -51.2682 -50.9346 -50.3728 -50.1212 -49.8508 -49.6801 -49.5483 -49.4252 -49.309 -49.2003 -49.0967 -48.9972 -48.8201 -48.6769 -48.588 -48.5079 -48.4323 -48.3581 -48.2863 -48.2165 -48.1477 -48.0793 -47.9776 -47.893 -47.8607 -47.8396 -47.8237 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Wed Jul 1 13:56:36 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
596 warnings in exp/tri5_ali/log/align_pass2.*.log
46 warnings in exp/tri5_ali/log/fmllr.*.log
607 warnings in exp/tri5_ali/log/align_pass1.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/104-pashto/release-current/conversational/dev
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Pashto_Babel104/dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/104-pashto/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Pashto_Babel104/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/104-pashto/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Wed Jul 1 13:58:54 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Pashto_Babel104/uem/db-v7_dev+eval-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel104b-v0.4bY_conv-dev/IARPA-babel104b-v0.4bY_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Wed Jul 1 13:58:55 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Pashto_Babel104/uem/db-v7_dev+eval-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-v7_dev+eval-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 198 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 136 files
filelist filelist.list contains 136 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Wed Jul 1 13:58:55 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_BP_104_04221_20120310_194031_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.105), segments file: (1.27 2.26)
Warning: BABEL_BP_104_04221_20120310_194031_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.091, 2.075), segments file: (1.27 2.26)
Warning: BABEL_BP_104_04221_20120310_194031_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (599.825, 600.040), segments file: (593.60 599.62)
Warning: BABEL_BP_104_04221_20120310_194031_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.695), segments file: (2.82 3.81)
Warning: BABEL_BP_104_04221_20120310_194031_outLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (595.945, 600.280), segments file: (593.91 595.46)
Warning: BABEL_BP_104_08861_20120226_050237_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.175), segments file: (3.04 4.04)
Warning: BABEL_BP_104_08861_20120226_050237_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (599.635, 600.020), segments file: (591.99 599.26)
Warning: BABEL_BP_104_08861_20120226_050237_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 1.545), segments file: (4.83 6.24)
Warning: BABEL_BP_104_08861_20120226_050237_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.545, 2.185), segments file: (4.83 6.24)
Warning: BABEL_BP_104_08861_20120226_050237_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.185, 4.885), segments file: (4.83 6.24)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Wed Jul 1 13:58:55 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 8282 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 8282 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Wed Jul 1 14:00:10 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Wed Jul 1 14:00:10 CDT 2015
---------------------------------------------------------------------
fstdeterminizestar --use-log=true 
fstminimizeencoded 
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstisstochastic data/lang/tmp/LG.fst 
0.000483187 -2.10481
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000483187 -2.10481
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fstdeterminizestar --use-log=true 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstminimizeencoded 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstrmepslocal 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.000861588 -2.1052
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Wed Jul 1 16:46:55 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Wed Jul 1 16:47:04 CDT 2015
lang = turkish, conf = conf/lang/105-turkish-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/105-turkish/release-current-b/conversational/training /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Turkish_Babel105/train.LimitedLP.official.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/105-turkish/release-current-b/conversational/training according to train.LimitedLP.official.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/105-turkish/release-current-b/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Turkish_Babel105/dev2hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/105-turkish/release-current-b/conversational/dev according to dev2hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/105-turkish/release-current-b/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Turkish_Babel105/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/105-turkish/release-current-b/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Wed Jul 1 16:47:04 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/105-turkish/release-babel105b-v0.4-rc1/conversational/reference_materials/lexicon.sub-train.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ;
local/prepare_lexicon.pl: Read 10110 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 12118 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 42 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 1 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 3 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Wed Jul 1 16:47:05 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 353 |' 'echo 10115 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 5 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 332 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 43 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 43 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 12 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 352 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 6 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 61 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Wed Jul 1 16:47:09 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 10114 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 128 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 10429 non-empty utterances from 128 files
local/prepare_acoustic_training_data.pl: Found 128 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 128 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 10429 lines each to text, utt2spk and segments
	Wrote 128 lines to wav.scp
	Wrote 121 lines to spk2utt
	Total # words = 72820 (including 2412 OOVs) + 14506 <silence>
	Amount of speech = 9.91 hours (including some due to <silence>)
	Average utterance length = 3.42 sec +/- 3.44 sec, and 6.98 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Wed Jul 1 16:47:11 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 18 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 1626 non-empty utterances from 18 files
local/prepare_acoustic_training_data.pl: Found 18 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 18 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 1626 lines each to text, utt2spk and segments
	Wrote 18 lines to wav.scp
	Wrote 18 lines to spk2utt
	Amount of speech = 1.50 hours (including some due to <silence>)
	Average utterance length = 3.32 sec +/- 3.17 sec, and 7.07 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Wed Jul 1 16:47:11 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_BP_105_12844_20120208_220114_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 8.825), segments file: (8.825 9.395)
Warning: BABEL_BP_105_12844_20120208_220114_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (8.825, 9.395), segments file: (8.825 9.395)
Warning: BABEL_BP_105_12844_20120208_220114_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 6.705), segments file: (6.705 7.405)
Warning: BABEL_BP_105_12844_20120208_220114_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (6.705, 7.405), segments file: (6.705 7.405)
Warning: BABEL_BP_105_12844_20120208_220114_outLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (595.025, 600.280), segments file: (593.935 595.025)
Warning: BABEL_BP_105_15146_20120106_223718_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 1.185), segments file: (5.145 5.745)
Warning: BABEL_BP_105_15146_20120106_223718_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.185, 1.545), segments file: (5.145 5.745)
Warning: BABEL_BP_105_15146_20120106_223718_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.545, 5.145), segments file: (5.145 5.745)
Warning: BABEL_BP_105_15146_20120106_223718_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (5.145, 5.745), segments file: (5.145 5.745)
Warning: BABEL_BP_105_15146_20120106_223718_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (593.975, 598.385), segments file: (589.375 593.975)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Wed Jul 1 16:47:11 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 10116 lines, 10116 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 84031 words, 10429 sentences
train.txt contains 73602 words, 10429 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 13142 words, 1626 sentences
data/srilm/dev.txt contains 11516 words, 1626 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30468.4  ppl=  208.16   ppl1=  442.326
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30481.7  ppl=  208.648  ppl1=  443.51
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30481.8  ppl=  208.648  ppl1=  443.511
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30493.9  ppl=  209.093  ppl1=  444.59
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30578    ppl=  212.197  ppl1=  452.129
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30578    ppl=  212.196  ppl1=  452.128
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30590.1  ppl=  212.649  ppl1=  453.228
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30780.5  ppl=  219.859  ppl1=  470.807
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30794.6  ppl=  220.406  ppl1=  472.145
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30799.8  ppl=  220.604  ppl1=  472.629
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30822.6  ppl=  221.488  ppl1=  474.789
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30869.8  ppl=  223.329  ppl1=  479.297
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30869.9  ppl=  223.33   ppl1=  479.298
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30882    ppl=  223.806  ppl1=  480.464
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30885    ppl=  223.923  ppl1=  480.75
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30899.4  ppl=  224.487  ppl1=  482.133
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30904.9  ppl=  224.707  ppl1=  482.673
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -30979.5  ppl=  227.66   ppl1=  489.917
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -31159.6  ppl=  234.96   ppl1=  507.887
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -31216.6  ppl=  237.318  ppl1=  513.708
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -31217.4  ppl=  237.35   ppl1=  513.786
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  1626  sentences,  11516  words,  0  OOVs  0  zeroprobs,  logprob=  -31310.6  ppl=  241.257  ppl1=  523.449
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Wed Jul 1 16:47:20 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -3.16577
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Wed Jul 1 16:47:20 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept all 10429 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 10429 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Wed Jul 1 16:48:36 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 10429 to 5000
utils/subset_data_dir.sh: reducing #utt from 10429 to 10000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Wed Jul 1 16:48:37 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
81 warnings in exp/mono/log/update.*.log
11544 warnings in exp/mono/log/align.*.*.log
483 warnings in exp/mono/log/acc.*.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Wed Jul 1 16:57:15 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
696 warnings in exp/tri1/log/acc.*.*.log
1590 warnings in exp/tri1/log/align.*.*.log
9 warnings in exp/tri1/log/update.*.log
1 warnings in exp/tri1/log/build_tree.log
3 warnings in exp/tri1/log/init_model.log
1 warnings in exp/tri1/log/compile_questions.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Wed Jul 1 17:03:58 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
951 warnings in exp/tri2/log/acc.*.*.log
1327 warnings in exp/tri2/log/align.*.*.log
1 warnings in exp/tri2/log/build_tree.log
117 warnings in exp/tri2/log/update.*.log
1 warnings in exp/tri2/log/compile_questions.log
60 warnings in exp/tri2/log/init_model.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Wed Jul 1 17:24:50 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1270 warnings in exp/tri3/log/align.*.*.log
1047 warnings in exp/tri3/log/acc.*.*.log
1 warnings in exp/tri3/log/compile_questions.log
57 warnings in exp/tri3/log/init_model.log
1 warnings in exp/tri3/log/build_tree.log
86 warnings in exp/tri3/log/update.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Wed Jul 1 17:40:26 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
1143 warnings in exp/tri4/log/align.*.*.log
1 warnings in exp/tri4/log/build_tree.log
58 warnings in exp/tri4/log/init_model.log
31 warnings in exp/tri4/log/lda_acc.*.log
949 warnings in exp/tri4/log/acc.*.*.log
80 warnings in exp/tri4/log/update.*.log
1 warnings in exp/tri4/log/compile_questions.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Wed Jul 1 17:47:19 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
69 warnings in exp/tri5/log/update.*.log
1 warnings in exp/tri5/log/build_tree.log
3 warnings in exp/tri5/log/est_alimdl.log
1023 warnings in exp/tri5/log/align.*.*.log
1 warnings in exp/tri5/log/compile_questions.log
128 warnings in exp/tri5/log/fmllr.*.*.log
27 warnings in exp/tri5/log/init_model.log
834 warnings in exp/tri5/log/acc.*.*.log
steps/train_sat.sh: Likelihood evolution:
-53.2616 -53.1671 -53.0138 -52.8926 -52.178 -51.4688 -51.0086 -50.6496 -50.3391 -49.7871 -49.531 -49.1953 -49.0134 -48.8707 -48.7431 -48.6246 -48.5136 -48.4108 -48.3114 -48.1315 -47.9932 -47.9064 -47.8258 -47.7478 -47.672 -47.5994 -47.5283 -47.4595 -47.3917 -47.2879 -47.2038 -47.1695 -47.1474 -47.1313 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Wed Jul 1 17:55:19 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
252 warnings in exp/tri5_ali/log/align_pass2.*.log
22 warnings in exp/tri5_ali/log/fmllr.*.log
273 warnings in exp/tri5_ali/log/align_pass1.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/105-turkish/release-current-b/conversational/dev
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Turkish_Babel105/dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/105-turkish/release-current-b/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Turkish_Babel105/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/105-turkish/release-current-b/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Wed Jul 1 17:57:00 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Turkish_Babel105/uem/db-dev+eval-v7-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel105b-v0.4_conv-dev/IARPA-babel105b-v0.4_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Wed Jul 1 17:57:00 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Turkish_Babel105/uem/db-dev+eval-v7-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-dev+eval-v7-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 194 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 127 files
filelist filelist.list contains 127 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Wed Jul 1 17:57:00 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_BP_105_11521_20120602_034839_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.035), segments file: (10.65 12.45)
Warning: BABEL_BP_105_11521_20120602_034839_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.035, 3.025), segments file: (10.65 12.45)
Warning: BABEL_BP_105_11521_20120602_034839_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (3.025, 4.875), segments file: (10.65 12.45)
Warning: BABEL_BP_105_11521_20120602_034839_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.875, 8.385), segments file: (10.65 12.45)
Warning: BABEL_BP_105_11521_20120602_034839_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (8.385, 9.325), segments file: (10.65 12.45)
Warning: BABEL_BP_105_11521_20120602_034839_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 3.665), segments file: (11.44 12.92)
Warning: BABEL_BP_105_11521_20120602_034839_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (3.665, 4.275), segments file: (11.44 12.92)
Warning: BABEL_BP_105_11521_20120602_034839_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.275, 8.165), segments file: (11.44 12.92)
Warning: BABEL_BP_105_11521_20120602_034839_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (8.165, 8.905), segments file: (11.44 12.92)
Warning: BABEL_BP_105_11521_20120602_034839_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (8.905, 11.465), segments file: (11.44 12.92)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Wed Jul 1 17:57:00 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 9131 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 9131 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Wed Jul 1 17:58:04 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Wed Jul 1 17:58:04 CDT 2015
---------------------------------------------------------------------
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
fstdeterminizestar --use-log=true 
fstminimizeencoded 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstisstochastic data/lang/tmp/LG.fst 
0.000481697 -3.1655
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000481697 -3.1655
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstminimizeencoded 
fstdeterminizestar --use-log=true 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstrmepslocal 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.000850109 -3.16543
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Wed Jul 1 19:43:00 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Wed Jul 1 19:43:05 CDT 2015
lang = tagalog, conf = conf/lang/106-tagalog-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/106-tagalog/release-current/conversational/training/ /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tagalog_Babel106/train.LimitedLP.official.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/106-tagalog/release-current/conversational/training/ according to train.LimitedLP.official.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/106-tagalog/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tagalog_Babel106/dev2hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/106-tagalog/release-current/conversational/dev according to dev2hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/106-tagalog/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tagalog_Babel106/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/106-tagalog/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Wed Jul 1 19:43:06 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/106-tagalog/release-babel106b-v0.2g-sub-train/conversational/reference_materials/lexicon.sub-train.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ;
local/prepare_lexicon.pl: Read 5562 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 8835 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 48 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 2 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 4 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Wed Jul 1 19:43:07 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 533 |' 'echo 5567 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 8 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 512 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 49 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 49 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 13 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 532 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 22 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 64 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Wed Jul 1 19:43:09 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 5566 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 134 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 11554 non-empty utterances from 134 files
local/prepare_acoustic_training_data.pl: Found 134 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 132 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 11554 lines each to text, utt2spk and segments
	Wrote 132 lines to wav.scp
	Wrote 120 lines to spk2utt
	Total # words = 70724 (including 1076 OOVs) + 18574 <silence>
	Amount of speech = 10.66 hours (including some due to <silence>)
	Average utterance length = 3.32 sec +/- 3.12 sec, and 6.12 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Wed Jul 1 19:43:11 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 26 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 2076 non-empty utterances from 26 files
local/prepare_acoustic_training_data.pl: Found 26 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 26 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 2076 lines each to text, utt2spk and segments
	Wrote 26 lines to wav.scp
	Wrote 23 lines to spk2utt
	Amount of speech = 1.98 hours (including some due to <silence>)
	Average utterance length = 3.44 sec +/- 3.24 sec, and 6.35 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Wed Jul 1 19:43:11 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_BP_106_05343_20120411_001147_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.545), segments file: (0.545 2.945)
Warning: BABEL_BP_106_05343_20120411_001147_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (597.635, 598.925), segments file: (593.285 597.635)
Warning: BABEL_BP_106_05343_20120411_001147_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (598.925, 599.865), segments file: (593.285 597.635)
Warning: BABEL_BP_106_05343_20120411_001147_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (599.865, 599.880), segments file: (593.285 597.635)
Warning: BABEL_BP_106_05343_20120411_001147_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.155), segments file: (0.155 1.355)
Warning: BABEL_BP_106_05343_20120411_001147_outLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (599.975, 600.260), segments file: (596.295 599.975)
Warning: BABEL_BP_106_11690_20120315_042036_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 6.635), segments file: (6.635 8.335)
Warning: BABEL_BP_106_11690_20120315_042036_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (598.415, 600.020), segments file: (596.605 598.415)
Warning: BABEL_BP_106_11690_20120315_042036_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 6.255), segments file: (6.255 7.995)
Warning: BABEL_BP_106_11690_20120315_042036_outLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (596.615, 597.635), segments file: (585.205 596.615)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Wed Jul 1 19:43:11 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 5568 lines, 5568 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 85221 words, 11554 sentences
train.txt contains 73667 words, 11554 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 15638 words, 2076 sentences
data/srilm/dev.txt contains 13562 words, 2076 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
warning: discount coeff 1 is out of range: 0
warning: discount coeff 6 is out of range: 1.07851
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32243.8  ppl=  115.316  ppl1=  238.513
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32298.5  ppl=  116.248  ppl1=  240.739
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32308.3  ppl=  116.416  ppl1=  241.139
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32314.2  ppl=  116.517  ppl1=  241.381
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32324    ppl=  116.685  ppl1=  241.783
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32333.2  ppl=  116.844  ppl1=  242.161
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32343    ppl=  117.013  ppl1=  242.564
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32443.9  ppl=  118.764  ppl1=  246.756
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32472    ppl=  119.256  ppl1=  247.934
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32516.4  ppl=  120.038  ppl1=  249.811
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32526.5  ppl=  120.216  ppl1=  250.238
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32529.5  ppl=  120.271  ppl1=  250.369
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32574.3  ppl=  121.066  ppl1=  252.277
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32583.9  ppl=  121.237  ppl1=  252.689
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32688.4  ppl=  123.117  ppl1=  257.212
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32704.1  ppl=  123.401  ppl1=  257.898
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32723.1  ppl=  123.747  ppl1=  258.731
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32826.3  ppl=  125.643  ppl1=  263.307
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32907.5  ppl=  127.153  ppl1=  266.961
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -32999.5  ppl=  128.887  ppl1=  271.163
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -33008.3  ppl=  129.056  ppl1=  271.572
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  2076  sentences,  13562  words,  0  OOVs  0  zeroprobs,  logprob=  -33108    ppl=  130.963  ppl1=  276.205
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Wed Jul 1 19:43:18 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -3.11085
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Wed Jul 1 19:43:18 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
It seems not all of the feature files were successfully processed (11553 != 11554);
consider using utils/fix_data_dir.sh data/train
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept 11553 utterances out of 11554
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 11553 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Wed Jul 1 19:44:43 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 11553 to 5000
utils/subset_data_dir.sh: reducing #utt from 11553 to 10000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Wed Jul 1 19:44:44 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
474 warnings in exp/mono/log/update.*.log
354 warnings in exp/mono/log/acc.*.*.log
10843 warnings in exp/mono/log/align.*.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Wed Jul 1 19:54:06 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 36 with no stats; corresponding phone list: 373 374 375 376 377 378 379 380 
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 40 with no stats; corresponding phone list: 417 418 419 420 
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 48 with no stats; corresponding phone list: 493 494 495 496 
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 50 with no stats; corresponding phone list: 505 506 507 508 509 510 511 512 
** The warnings above about 'no stats' generally mean you have phones **
** (or groups of phones) in your phone set that had no corresponding data. **
** You should probably figure out whether something went wrong, **
** or whether your data just doesn't happen to have examples of those **
** phones. **
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
155 warnings in exp/tri1/log/update.*.log
14 warnings in exp/tri1/log/init_model.log
1243 warnings in exp/tri1/log/align.*.*.log
370 warnings in exp/tri1/log/acc.*.*.log
1 warnings in exp/tri1/log/build_tree.log
1 warnings in exp/tri1/log/compile_questions.log
4 warnings in exp/tri1/log/questions.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Wed Jul 1 20:01:32 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 40 with no stats; corresponding phone list: 417 418 419 420 
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 48 with no stats; corresponding phone list: 493 494 495 496 
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 50 with no stats; corresponding phone list: 505 506 507 508 509 510 511 512 
** The warnings above about 'no stats' generally mean you have phones **
** (or groups of phones) in your phone set that had no corresponding data. **
** You should probably figure out whether something went wrong, **
** or whether your data just doesn't happen to have examples of those **
** phones. **
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1095 warnings in exp/tri2/log/align.*.*.log
3 warnings in exp/tri2/log/questions.log
374 warnings in exp/tri2/log/acc.*.*.log
101 warnings in exp/tri2/log/init_model.log
271 warnings in exp/tri2/log/update.*.log
1 warnings in exp/tri2/log/compile_questions.log
1 warnings in exp/tri2/log/build_tree.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Wed Jul 1 20:45:59 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 48 with no stats; corresponding phone list: 493 494 495 496 
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 50 with no stats; corresponding phone list: 505 506 507 508 509 510 511 512 
** The warnings above about 'no stats' generally mean you have phones **
** (or groups of phones) in your phone set that had no corresponding data. **
** You should probably figure out whether something went wrong, **
** or whether your data just doesn't happen to have examples of those **
** phones. **
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri3/log/compile_questions.log
225 warnings in exp/tri3/log/update.*.log
87 warnings in exp/tri3/log/init_model.log
1077 warnings in exp/tri3/log/align.*.*.log
2 warnings in exp/tri3/log/questions.log
359 warnings in exp/tri3/log/acc.*.*.log
1 warnings in exp/tri3/log/build_tree.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Wed Jul 1 21:12:10 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 50 with no stats; corresponding phone list: 505 506 507 508 509 510 511 512 
This is a bad warning.
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
400 warnings in exp/tri4/log/acc.*.*.log
982 warnings in exp/tri4/log/align.*.*.log
1 warnings in exp/tri4/log/questions.log
1 warnings in exp/tri4/log/build_tree.log
1 warnings in exp/tri4/log/compile_questions.log
244 warnings in exp/tri4/log/update.*.log
10 warnings in exp/tri4/log/lda_acc.*.log
106 warnings in exp/tri4/log/init_model.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Wed Jul 1 21:27:42 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 48 with no stats; corresponding phone list: 493 494 495 496 
WARNING (gmm-init-model:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 50 with no stats; corresponding phone list: 505 506 507 508 509 510 511 512 
This is a bad warning.
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
64 warnings in exp/tri5/log/init_model.log
64 warnings in exp/tri5/log/fmllr.*.*.log
1 warnings in exp/tri5/log/build_tree.log
8 warnings in exp/tri5/log/est_alimdl.log
508 warnings in exp/tri5/log/acc.*.*.log
923 warnings in exp/tri5/log/align.*.*.log
1 warnings in exp/tri5/log/compile_questions.log
285 warnings in exp/tri5/log/update.*.log
2 warnings in exp/tri5/log/questions.log
steps/train_sat.sh: Likelihood evolution:
-53.9177 -53.7528 -53.5931 -53.4051 -52.5099 -51.715 -51.3074 -50.9709 -50.6939 -50.1663 -49.9097 -49.6094 -49.445 -49.3188 -49.2002 -49.085 -48.9767 -48.8728 -48.7744 -48.5922 -48.455 -48.3694 -48.2911 -48.2157 -48.1416 -48.0701 -48.0014 -47.9339 -47.8668 -47.7633 -47.6843 -47.6518 -47.6296 -47.6124 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Wed Jul 1 21:45:31 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
258 warnings in exp/tri5_ali/log/align_pass1.*.log
232 warnings in exp/tri5_ali/log/align_pass2.*.log
14 warnings in exp/tri5_ali/log/fmllr.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/106-tagalog/release-current/conversational/dev
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tagalog_Babel106/dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/106-tagalog/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tagalog_Babel106/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/106-tagalog/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Wed Jul 1 21:49:13 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tagalog_Babel106/uem/v18/db-tag-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel106b-v0.2g_conv-dev/IARPA-babel106b-v0.2g_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Wed Jul 1 21:49:13 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tagalog_Babel106/uem/v18/db-tag-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-tag-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 241 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 146 files
filelist filelist.list contains 146 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Wed Jul 1 21:49:15 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_BP_106_05343_20120411_001147_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.545), segments file: (1.74 3.02)
Warning: BABEL_BP_106_05343_20120411_001147_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (598.925, 599.865), segments file: (596.56 597.70)
Warning: BABEL_BP_106_05343_20120411_001147_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (599.865, 599.880), segments file: (596.56 597.70)
Warning: BABEL_BP_106_05343_20120411_001147_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.155), segments file: (6.99 8.21)
Warning: BABEL_BP_106_05343_20120411_001147_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.555, 1.355), segments file: (6.99 8.21)
Warning: BABEL_BP_106_05343_20120411_001147_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.355, 2.955), segments file: (6.99 8.21)
Warning: BABEL_BP_106_05343_20120411_001147_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.955, 3.485), segments file: (6.99 8.21)
Warning: BABEL_BP_106_05343_20120411_001147_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (3.485, 4.585), segments file: (6.99 8.21)
Warning: BABEL_BP_106_05343_20120411_001147_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.585, 5.155), segments file: (6.99 8.21)
Warning: BABEL_BP_106_05343_20120411_001147_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (5.155, 7.065), segments file: (6.99 8.21)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Wed Jul 1 21:49:15 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 13773 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 13773 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Wed Jul 1 21:51:35 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Wed Jul 1 21:51:35 CDT 2015
---------------------------------------------------------------------
fstdeterminizestar --use-log=true 
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
fstminimizeencoded 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstisstochastic data/lang/tmp/LG.fst 
0.000482993 -3.11054
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000482993 -3.11054
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstdeterminizestar --use-log=true 
fstminimizeencoded 
fstrmepslocal 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.000821125 -3.11084
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Thu Jul 2 01:42:36 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Thu Jul 2 01:42:43 CDT 2015
lang = vietnamese, conf = conf/lang/107-vietnamese-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/107-vietnamese/release-current/conversational/training/ /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Vietnamese_Babel107/train.LimitedLP.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/107-vietnamese/release-current/conversational/training/ according to train.LimitedLP.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/107-vietnamese/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Vietnamese_Babel107/dev.2hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/107-vietnamese/release-current/conversational/dev according to dev.2hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/107-vietnamese/release-current/conversational/dev/ /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Vietnamese_Babel107/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/107-vietnamese/release-current/conversational/dev/ according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Thu Jul 2 01:42:47 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/107-vietnamese/release-current/conversational/reference_materials/lexicon.sub-train.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ; i@U = i ə ʊ ; oaI = o a ɪ ; oaI: = o a ɪː ; u@I = u ə ɪ ; uI@ = u ɪ ə ; 1@I = ɨ ə ɪ ; 1@U = ɨ ə ʊ ; a:I = aː ɪ ; a:U = aː ʊ ; aU = a ʊ ; @U = ə ʊ ; aI = a ɪ ; @I = ə ɪ ; EU = ɛ ʊ ; eU = e ʊ ; i@ = i ə ; iU = i ʊ ; Oa: = ɔ aː ; Oa = ɔ a ; OE = ɔ ɛ ; OI = ɔ ɪ ; oI = o ɪ ; @:I = əː ɪ ; u@ = u ə ; 1@ = ɨ ə ; ue = u e ; uI = u ɪ ; 1I = ɨ ɪ ; u@: = u əː ; 1U = ɨ ʊ ; ui: = u iː ;
local/prepare_lexicon.pl: Read 3205 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 4938 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 40 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 6 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 8 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Thu Jul 2 01:42:47 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 929 |' 'echo 3210 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 8 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 908 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 41 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 41 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 17 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 928 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 68 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 66 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Thu Jul 2 01:42:50 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 3209 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 126 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 10174 non-empty utterances from 126 files
local/prepare_acoustic_training_data.pl: Found 126 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 126 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 10174 lines each to text, utt2spk and segments
	Wrote 126 lines to wav.scp
	Wrote 121 lines to spk2utt
	Total # words = 117587 (including 328 OOVs) + 22260 <silence>
	Amount of speech = 10.98 hours (including some due to <silence>)
	Average utterance length = 3.88 sec +/- 3.34 sec, and 11.56 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Thu Jul 2 01:42:53 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 27 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 1928 non-empty utterances from 27 files
local/prepare_acoustic_training_data.pl: Found 27 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 27 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 1928 lines each to text, utt2spk and segments
	Wrote 27 lines to wav.scp
	Wrote 27 lines to spk2utt
	Amount of speech = 2.45 hours (including some due to <silence>)
	Average utterance length = 4.57 sec +/- 3.79 sec, and 12.93 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Thu Jul 2 01:42:53 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_BP_107_12120_20120704_024505_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 3.435), segments file: (3.435 4.244875)
Warning: BABEL_BP_107_12120_20120704_024505_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (3.435, 4.245), segments file: (3.435 4.244875)
Warning: BABEL_BP_107_12248_20120614_183345_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 6.815), segments file: (6.815 12.885)
Warning: BABEL_BP_107_12248_20120614_183345_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (6.815, 12.885), segments file: (6.815 12.885)
Warning: BABEL_BP_107_12248_20120614_183345_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (599.725, 599.960), segments file: (599.215 599.725)
Warning: BABEL_BP_107_12963_20120509_002346_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.915), segments file: (13.115 16.605)
Warning: BABEL_BP_107_12963_20120509_002346_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.915, 5.195), segments file: (13.115 16.605)
Warning: BABEL_BP_107_12963_20120509_002346_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (5.195, 6.365), segments file: (13.115 16.605)
Warning: BABEL_BP_107_12963_20120509_002346_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (6.365, 7.535), segments file: (13.115 16.605)
Warning: BABEL_BP_107_12963_20120509_002346_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (7.535, 9.425), segments file: (13.115 16.605)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Thu Jul 2 01:42:53 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 3211 lines, 3211 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 136607 words, 10174 sentences
train.txt contains 126433 words, 10174 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 28574 words, 1928 sentences
data/srilm/dev.txt contains 26646 words, 1928 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62564.1  ppl=  154.72   ppl1=  222.831
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62588.6  ppl=  155.026  ppl1=  223.302
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62631.4  ppl=  155.562  ppl1=  224.13
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62640.7  ppl=  155.678  ppl1=  224.31
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62678.5  ppl=  156.153  ppl1=  225.044
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62723.1  ppl=  156.715  ppl1=  225.912
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62731.9  ppl=  156.826  ppl1=  226.084
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62738.8  ppl=  156.914  ppl1=  226.22
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62820.6  ppl=  157.951  ppl1=  227.824
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62823.7  ppl=  157.99   ppl1=  227.885
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62842.5  ppl=  158.231  ppl1=  228.257
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62845.6  ppl=  158.27   ppl1=  228.317
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62861.8  ppl=  158.476  ppl1=  228.636
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -62883.7  ppl=  158.757  ppl1=  229.07
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -63153.4  ppl=  162.244  ppl1=  234.47
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -63263    ppl=  163.683  ppl1=  236.702
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -63270.6  ppl=  163.785  ppl1=  236.859
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -63335    ppl=  164.636  ppl1=  238.179
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -63338    ppl=  164.677  ppl1=  238.242
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -63376.1  ppl=  165.183  ppl1=  239.027
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -63477.2  ppl=  166.534  ppl1=  241.125
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  1928  sentences,  26646  words,  0  OOVs  0  zeroprobs,  logprob=  -63594.2  ppl=  168.112  ppl1=  243.575
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Thu Jul 2 01:43:09 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -1.88929
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Thu Jul 2 01:43:10 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept all 10174 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 10174 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Thu Jul 2 01:45:51 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 10174 to 5000
utils/subset_data_dir.sh: reducing #utt from 10174 to 10000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Thu Jul 2 01:45:52 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
621 warnings in exp/mono/log/acc.*.*.log
62 warnings in exp/mono/log/update.*.log
14589 warnings in exp/mono/log/align.*.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Thu Jul 2 02:08:22 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
6 warnings in exp/tri1/log/update.*.log
384 warnings in exp/tri1/log/acc.*.*.log
1 warnings in exp/tri1/log/build_tree.log
1 warnings in exp/tri1/log/compile_questions.log
5 warnings in exp/tri1/log/init_model.log
1806 warnings in exp/tri1/log/align.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Thu Jul 2 02:22:40 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri2/log/compile_questions.log
349 warnings in exp/tri2/log/acc.*.*.log
1318 warnings in exp/tri2/log/align.*.*.log
87 warnings in exp/tri2/log/init_model.log
166 warnings in exp/tri2/log/update.*.log
1 warnings in exp/tri2/log/build_tree.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Thu Jul 2 02:56:14 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
315 warnings in exp/tri3/log/acc.*.*.log
63 warnings in exp/tri3/log/init_model.log
1 warnings in exp/tri3/log/compile_questions.log
1 warnings in exp/tri3/log/build_tree.log
118 warnings in exp/tri3/log/update.*.log
1283 warnings in exp/tri3/log/align.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Thu Jul 2 03:23:00 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
1015 warnings in exp/tri4/log/align.*.*.log
1 warnings in exp/tri4/log/compile_questions.log
141 warnings in exp/tri4/log/init_model.log
217 warnings in exp/tri4/log/update.*.log
281 warnings in exp/tri4/log/acc.*.*.log
9 warnings in exp/tri4/log/lda_acc.*.log
1 warnings in exp/tri4/log/build_tree.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Thu Jul 2 03:34:09 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
49 warnings in exp/tri5/log/fmllr.*.*.log
133 warnings in exp/tri5/log/update.*.log
1 warnings in exp/tri5/log/build_tree.log
1 warnings in exp/tri5/log/compile_questions.log
64 warnings in exp/tri5/log/init_model.log
2 warnings in exp/tri5/log/est_alimdl.log
497 warnings in exp/tri5/log/acc.*.*.log
938 warnings in exp/tri5/log/align.*.*.log
steps/train_sat.sh: Likelihood evolution:
-54.1191 -54.0556 -53.7917 -53.608 -52.7629 -52.0141 -51.5712 -51.2231 -50.94 -50.372 -50.1084 -49.7946 -49.6152 -49.4832 -49.3622 -49.2445 -49.132 -49.0263 -48.9252 -48.7426 -48.5971 -48.5026 -48.4172 -48.335 -48.2547 -48.1754 -48.0969 -48.0207 -47.948 -47.8385 -47.7513 -47.7141 -47.6906 -47.6726 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Thu Jul 2 03:53:09 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
219 warnings in exp/tri5_ali/log/align_pass1.*.log
199 warnings in exp/tri5_ali/log/align_pass2.*.log
12 warnings in exp/tri5_ali/log/fmllr.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/107-vietnamese/release-current/conversational/dev/
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Vietnamese_Babel107/dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/107-vietnamese/release-current/conversational/dev/ /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Vietnamese_Babel107/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/107-vietnamese/release-current/conversational/dev/ according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Thu Jul 2 03:57:12 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Vietnamese_Babel107/uem/conv-eval/db-v8-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel107b-v0.7_conv-dev/IARPA-babel107b-v0.7_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Thu Jul 2 03:57:12 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Vietnamese_Babel107/uem/conv-eval/db-v8-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-v8-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 981 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 132 files
filelist filelist.list contains 132 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Thu Jul 2 03:57:14 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_BP_107_11031_20120617_182613_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.785), segments file: (6.88 17.49)
Warning: BABEL_BP_107_11031_20120617_182613_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.785, 4.025), segments file: (6.88 17.49)
Warning: BABEL_BP_107_11031_20120617_182613_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.025, 5.415), segments file: (6.88 17.49)
Warning: BABEL_BP_107_11031_20120617_182613_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (5.415, 5.845), segments file: (6.88 17.49)
Warning: BABEL_BP_107_11031_20120617_182613_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (5.845, 7.045), segments file: (6.88 17.49)
Warning: BABEL_BP_107_11031_20120617_182613_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (586.945, 589.955), segments file: (579.31 586.49)
Warning: BABEL_BP_107_11031_20120617_182613_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (589.955, 590.445), segments file: (579.31 586.49)
Warning: BABEL_BP_107_11031_20120617_182613_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (590.445, 595.375), segments file: (579.31 586.49)
Warning: BABEL_BP_107_11031_20120617_182613_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (595.375, 595.735), segments file: (579.31 586.49)
Warning: BABEL_BP_107_11031_20120617_182613_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (595.735, 596.835), segments file: (579.31 586.49)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Thu Jul 2 03:57:14 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 9704 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 9704 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Thu Jul 2 03:59:39 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Thu Jul 2 03:59:39 CDT 2015
---------------------------------------------------------------------
fstminimizeencoded 
fstdeterminizestar --use-log=true 
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstisstochastic data/lang/tmp/LG.fst 
0.000481747 -1.88953
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000481747 -1.88953
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fstrmepslocal 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstminimizeencoded 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstdeterminizestar --use-log=true 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.000826903 -1.88981
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Thu Jul 2 09:55:04 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Thu Jul 2 09:55:16 CDT 2015
lang = haitian, conf = conf/lang/201-haitian-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/201-haitian/release-current/conversational/training/ /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Haitian_Babel201/train.LimitedLP.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/201-haitian/release-current/conversational/training/ according to train.LimitedLP.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/201-haitian/release-current/conversational/dev/ /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Haitian_Babel201/dev.2hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/201-haitian/release-current/conversational/dev/ according to dev.2hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/201-haitian/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Haitian_Babel201/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/201-haitian/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Thu Jul 2 09:55:17 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/201-haitian/release-current/conversational/reference_materials/lexicon.sub-train.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ;
local/prepare_lexicon.pl: Read 4897 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 4908 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 32 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 0 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 2 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Thu Jul 2 09:55:18 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 149 |' 'echo 4902 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 6 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 128 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 33 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 33 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 11 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 148 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 37 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 99 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Thu Jul 2 09:55:21 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 4901 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 126 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 9570 non-empty utterances from 126 files
local/prepare_acoustic_training_data.pl: Found 113 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 113 .sph files
local/prepare_acoustic_training_data.pl: Found 13 .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 13 .sph files
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 9570 lines each to text, utt2spk and segments
	Wrote 126 lines to wav.scp
	Wrote 120 lines to spk2utt
	Total # words = 102300 (including 3336 OOVs) + 16323 <silence>
	Amount of speech = 11.36 hours (including some due to <silence>)
	Average utterance length = 4.27 sec +/- 3.66 sec, and 10.69 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Thu Jul 2 09:55:23 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 26 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 2209 non-empty utterances from 26 files
local/prepare_acoustic_training_data.pl: Found 23 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 23 .sph files
local/prepare_acoustic_training_data.pl: Found 3 .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 3 .sph files
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 2209 lines each to text, utt2spk and segments
	Wrote 26 lines to wav.scp
	Wrote 26 lines to spk2utt
	Amount of speech = 2.27 hours (including some due to <silence>)
	Average utterance length = 3.70 sec +/- 3.36 sec, and 10.12 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Thu Jul 2 09:55:24 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_201_10019_20130527_022947_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.955), segments file: (6.825 7.305)
Warning: BABEL_OP1_201_10019_20130527_022947_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.955, 6.015), segments file: (6.825 7.305)
Warning: BABEL_OP1_201_10019_20130527_022947_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (6.015, 6.825), segments file: (6.825 7.305)
Warning: BABEL_OP1_201_10019_20130527_022947_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (6.825, 7.305), segments file: (6.825 7.305)
Warning: BABEL_OP1_201_14440_20130302_012105_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.965), segments file: (4.695 5.275)
Warning: BABEL_OP1_201_14440_20130302_012105_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.965, 4.695), segments file: (4.695 5.275)
Warning: BABEL_OP1_201_14440_20130302_012105_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.695, 5.275), segments file: (4.695 5.275)
Warning: BABEL_OP1_201_15638_20130305_060156_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 8.215), segments file: (8.215 10.645)
Warning: BABEL_OP1_201_15638_20130305_060156_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (8.215, 10.645), segments file: (8.215 10.645)
Warning: BABEL_OP1_201_15638_20130305_060156_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (599.605, 599.960), segments file: (598.085 599.605)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Thu Jul 2 09:55:24 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 4903 lines, 4903 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 115085 words, 9570 sentences
train.txt contains 105515 words, 9570 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 25186 words, 2209 sentences
data/srilm/dev.txt contains 22977 words, 2209 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
warning: discount coeff 1 is out of range: 0
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14307
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14307
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14307
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14307
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14307
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14307
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14307
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53344.6  ppl=  131.228  ppl1=  209.725
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53346.7  ppl=  131.253  ppl1=  209.77
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53351.4  ppl=  131.31   ppl1=  209.87
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53377.6  ppl=  131.625  ppl1=  210.421
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53390.3  ppl=  131.777  ppl1=  210.689
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53395    ppl=  131.834  ppl1=  210.788
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53421.2  ppl=  132.15   ppl1=  211.343
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53452.7  ppl=  132.531  ppl1=  212.01
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53514.7  ppl=  133.285  ppl1=  213.332
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53517.4  ppl=  133.317  ppl1=  213.388
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53521.2  ppl=  133.364  ppl1=  213.471
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53594.7  ppl=  134.263  ppl1=  215.048
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53650.4  ppl=  134.948  ppl1=  216.252
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53656.9  ppl=  135.029  ppl1=  216.394
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53965.2  ppl=  138.889  ppl1=  223.184
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53969.9  ppl=  138.949  ppl1=  223.289
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -53996.1  ppl=  139.282  ppl1=  223.876
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -54155.9  ppl=  141.331  ppl1=  227.489
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -54262.2  ppl=  142.712  ppl1=  229.927
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -54315.7  ppl=  143.411  ppl1=  231.161
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -54328.6  ppl=  143.58   ppl1=  231.461
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  2209  sentences,  22977  words,  0  OOVs  0  zeroprobs,  logprob=  -54562.2  ppl=  146.679  ppl1=  236.942
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Thu Jul 2 09:55:38 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -3.04229
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Thu Jul 2 09:55:40 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept all 9570 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 9570 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Thu Jul 2 09:58:30 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 9570 to 5000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Thu Jul 2 09:58:30 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
788 warnings in exp/mono/log/acc.*.*.log
13749 warnings in exp/mono/log/align.*.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Thu Jul 2 10:20:21 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
3 warnings in exp/tri1/log/init_model.log
1 warnings in exp/tri1/log/compile_questions.log
1 warnings in exp/tri1/log/build_tree.log
498 warnings in exp/tri1/log/acc.*.*.log
1933 warnings in exp/tri1/log/align.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Thu Jul 2 10:34:16 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1442 warnings in exp/tri2/log/align.*.*.log
125 warnings in exp/tri2/log/update.*.log
1 warnings in exp/tri2/log/build_tree.log
569 warnings in exp/tri2/log/acc.*.*.log
94 warnings in exp/tri2/log/init_model.log
1 warnings in exp/tri2/log/compile_questions.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Thu Jul 2 11:06:23 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
553 warnings in exp/tri3/log/acc.*.*.log
1 warnings in exp/tri3/log/build_tree.log
1 warnings in exp/tri3/log/compile_questions.log
82 warnings in exp/tri3/log/init_model.log
89 warnings in exp/tri3/log/update.*.log
1386 warnings in exp/tri3/log/align.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Thu Jul 2 11:32:15 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
110 warnings in exp/tri4/log/init_model.log
1 warnings in exp/tri4/log/build_tree.log
137 warnings in exp/tri4/log/update.*.log
444 warnings in exp/tri4/log/acc.*.*.log
1153 warnings in exp/tri4/log/align.*.*.log
16 warnings in exp/tri4/log/lda_acc.*.log
1 warnings in exp/tri4/log/compile_questions.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Thu Jul 2 11:47:45 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
64 warnings in exp/tri5/log/fmllr.*.*.log
1037 warnings in exp/tri5/log/align.*.*.log
55 warnings in exp/tri5/log/init_model.log
3 warnings in exp/tri5/log/est_alimdl.log
55 warnings in exp/tri5/log/update.*.log
1 warnings in exp/tri5/log/build_tree.log
1 warnings in exp/tri5/log/compile_questions.log
508 warnings in exp/tri5/log/acc.*.*.log
steps/train_sat.sh: Likelihood evolution:
-54.8034 -54.3972 -54.209 -54.0396 -53.3373 -52.7315 -52.2681 -51.9455 -51.6704 -51.1385 -50.8873 -50.6322 -50.4797 -50.364 -50.2585 -50.1554 -50.0557 -49.9622 -49.8742 -49.7078 -49.5742 -49.4875 -49.4098 -49.3388 -49.2721 -49.2072 -49.1427 -49.0788 -49.0158 -48.9183 -48.8396 -48.8074 -48.7852 -48.768 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Thu Jul 2 12:05:43 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
13 warnings in exp/tri5_ali/log/fmllr.*.log
285 warnings in exp/tri5_ali/log/align_pass1.*.log
248 warnings in exp/tri5_ali/log/align_pass2.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/201-haitian/release-current/conversational/dev
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Haitian_Babel201/dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/201-haitian/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Haitian_Babel201/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/201-haitian/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Thu Jul 2 12:09:37 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Haitian_Babel201/uem/db-dev-jhuseg-v7-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel201b-v0.2b_conv-dev/IARPA-babel201b-v0.2b_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Thu Jul 2 12:09:37 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Haitian_Babel201/uem/db-dev-jhuseg-v7-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-dev-jhuseg-v7-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 0 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 126 files
filelist filelist.list contains 126 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Thu Jul 2 12:09:38 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_201_10019_20130527_022947_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.955), segments file: (3.35 7.41)
Warning: BABEL_OP1_201_10019_20130527_022947_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.955, 6.015), segments file: (3.35 7.41)
Warning: BABEL_OP1_201_10019_20130527_022947_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 1.125), segments file: (8.01 9.86)
Warning: BABEL_OP1_201_10019_20130527_022947_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.125, 1.715), segments file: (8.01 9.86)
Warning: BABEL_OP1_201_10019_20130527_022947_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.715, 7.915), segments file: (8.01 9.86)
Warning: BABEL_OP1_201_10019_20130527_022947_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (7.915, 8.485), segments file: (8.01 9.86)
Warning: BABEL_OP1_201_10319_20130306_021244_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.445), segments file: (4.36 5.01)
Warning: BABEL_OP1_201_10319_20130306_021244_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.445, 2.865), segments file: (4.36 5.01)
Warning: BABEL_OP1_201_10319_20130306_021244_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.865, 4.335), segments file: (4.36 5.01)
Warning: BABEL_OP1_201_10319_20130306_021244_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.335, 5.075), segments file: (4.36 5.01)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Thu Jul 2 12:09:38 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 11747 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 11747 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Thu Jul 2 12:11:56 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Thu Jul 2 12:11:56 CDT 2015
---------------------------------------------------------------------
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
fstdeterminizestar --use-log=true 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstminimizeencoded 
fstisstochastic data/lang/tmp/LG.fst 
0.000482429 -3.0426
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000482429 -3.0426
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fstdeterminizestar --use-log=true 
fstminimizeencoded 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstrmepslocal 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.000844464 -3.04251
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Thu Jul 2 16:36:10 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Thu Jul 2 16:36:20 CDT 2015
lang = lao, conf = conf/lang/203-lao-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/203-lao/release-current/conversational/training /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Lao_Babel203/train.LimitedLP.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/203-lao/release-current/conversational/training according to train.LimitedLP.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/203-lao/release-current/conversational/dev/ /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Lao_Babel203/dev.2hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/203-lao/release-current/conversational/dev/ according to dev.2hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/203-lao/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Lao_Babel203/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/203-lao/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Thu Jul 2 16:36:22 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/203-lao/release-current/conversational/reference_materials/lexicon.sub-train.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
	Romanized forms of words expected in the dictionary
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ;
local/prepare_lexicon.pl: Read 3080 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 4194 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 42 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 6 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 7 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Thu Jul 2 16:36:23 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 997 |' 'echo 3085 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 5 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 976 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 43 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 43 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 16 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 996 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 59 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 56 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Thu Jul 2 16:36:26 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 3084 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 127 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 10923 non-empty utterances from 127 files
local/prepare_acoustic_training_data.pl: Found 117 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 117 .sph files
local/prepare_acoustic_training_data.pl: Found 10 .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 10 .sph files
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 10923 lines each to text, utt2spk and segments
	Wrote 127 lines to wav.scp
	Wrote 119 lines to spk2utt
	Total # words = 96462 (including 1325 OOVs) + 16824 <silence>
	Amount of speech = 10.51 hours (including some due to <silence>)
	Average utterance length = 3.46 sec +/- 3.14 sec, and 8.83 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Thu Jul 2 16:36:28 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 35 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 2121 non-empty utterances from 35 files
local/prepare_acoustic_training_data.pl: Found 33 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 33 .sph files
local/prepare_acoustic_training_data.pl: Found 2 .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 2 .sph files
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 2121 lines each to text, utt2spk and segments
	Wrote 35 lines to wav.scp
	Wrote 23 lines to spk2utt
	Amount of speech = 2.01 hours (including some due to <silence>)
	Average utterance length = 3.41 sec +/- 3.11 sec, and 8.12 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Thu Jul 2 16:36:29 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_203_10188_20130220_225432_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 1.665), segments file: (15.045 15.795)
Warning: BABEL_OP1_203_10188_20130220_225432_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.665, 2.055), segments file: (15.045 15.795)
Warning: BABEL_OP1_203_10188_20130220_225432_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.055, 8.550), segments file: (15.045 15.795)
Warning: BABEL_OP1_203_10188_20130220_225432_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (8.550, 15.045), segments file: (15.045 15.795)
Warning: BABEL_OP1_203_10188_20130220_225432_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (15.045, 15.795), segments file: (15.045 15.795)
Warning: BABEL_OP1_203_10188_20130220_225432_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.915), segments file: (17.495 18.255)
Warning: BABEL_OP1_203_10188_20130220_225432_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.915, 1.285), segments file: (17.495 18.255)
Warning: BABEL_OP1_203_10188_20130220_225432_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.285, 12.375), segments file: (17.495 18.255)
Warning: BABEL_OP1_203_10188_20130220_225432_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (12.375, 13.085), segments file: (17.495 18.255)
Warning: BABEL_OP1_203_10188_20130220_225432_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (13.085, 17.495), segments file: (17.495 18.255)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Thu Jul 2 16:36:29 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 3086 lines, 3086 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 109172 words, 10923 sentences
train.txt contains 98249 words, 10923 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 19673 words, 2121 sentences
data/srilm/dev.txt contains 17552 words, 2121 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
warning: discount coeff 1 is out of range: -0
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41160.8  ppl=  123.665  ppl1=  221.349
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41170.9  ppl=  123.812  ppl1=  221.644
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41173.5  ppl=  123.849  ppl1=  221.718
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41197.3  ppl=  124.195  ppl1=  222.411
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41200.2  ppl=  124.237  ppl1=  222.496
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41201.8  ppl=  124.26   ppl1=  222.541
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41207.4  ppl=  124.342  ppl1=  222.708
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41236.7  ppl=  124.769  ppl1=  223.564
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41245.4  ppl=  124.896  ppl1=  223.82
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41249.3  ppl=  124.953  ppl1=  223.935
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41267.2  ppl=  125.215  ppl1=  224.46
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41279.3  ppl=  125.393  ppl1=  224.818
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41325.7  ppl=  126.076  ppl1=  226.191
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41342.9  ppl=  126.33   ppl1=  226.701
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41558    ppl=  129.551  ppl1=  233.19
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41568.2  ppl=  129.705  ppl1=  233.501
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41597.4  ppl=  130.15   ppl1=  234.398
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41660.5  ppl=  131.114  ppl1=  236.346
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41737.1  ppl=  132.295  ppl1=  238.733
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41771.2  ppl=  132.824  ppl1=  239.804
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41772.9  ppl=  132.85   ppl1=  239.856
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  2121  sentences,  17552  words,  0  OOVs  0  zeroprobs,  logprob=  -41910.9  ppl=  135.014  ppl1=  244.24
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Thu Jul 2 16:36:43 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -2.4241
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Thu Jul 2 16:36:46 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept all 10923 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 10923 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Thu Jul 2 16:39:23 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 10923 to 5000
utils/subset_data_dir.sh: reducing #utt from 10923 to 10000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Thu Jul 2 16:39:24 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
1421 warnings in exp/mono/log/acc.*.*.log
13682 warnings in exp/mono/log/align.*.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Thu Jul 2 16:57:36 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
2 warnings in exp/tri1/log/init_model.log
1 warnings in exp/tri1/log/compile_questions.log
850 warnings in exp/tri1/log/acc.*.*.log
1 warnings in exp/tri1/log/build_tree.log
1560 warnings in exp/tri1/log/align.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Thu Jul 2 17:11:20 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri2/log/build_tree.log
462 warnings in exp/tri2/log/acc.*.*.log
52 warnings in exp/tri2/log/init_model.log
1236 warnings in exp/tri2/log/align.*.*.log
84 warnings in exp/tri2/log/update.*.log
1 warnings in exp/tri2/log/compile_questions.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Thu Jul 2 17:44:52 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
75 warnings in exp/tri3/log/update.*.log
1180 warnings in exp/tri3/log/align.*.*.log
51 warnings in exp/tri3/log/init_model.log
452 warnings in exp/tri3/log/acc.*.*.log
1 warnings in exp/tri3/log/build_tree.log
1 warnings in exp/tri3/log/compile_questions.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Thu Jul 2 18:11:28 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
70 warnings in exp/tri4/log/init_model.log
167 warnings in exp/tri4/log/update.*.log
1104 warnings in exp/tri4/log/align.*.*.log
1 warnings in exp/tri4/log/compile_questions.log
13 warnings in exp/tri4/log/lda_acc.*.log
1 warnings in exp/tri4/log/build_tree.log
422 warnings in exp/tri4/log/acc.*.*.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Thu Jul 2 18:27:23 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
3 warnings in exp/tri5/log/est_alimdl.log
75 warnings in exp/tri5/log/update.*.log
744 warnings in exp/tri5/log/align.*.*.log
1 warnings in exp/tri5/log/build_tree.log
37 warnings in exp/tri5/log/init_model.log
311 warnings in exp/tri5/log/acc.*.*.log
46 warnings in exp/tri5/log/fmllr.*.*.log
1 warnings in exp/tri5/log/compile_questions.log
steps/train_sat.sh: Likelihood evolution:
-53.2685 -52.8421 -52.5278 -52.2303 -51.1778 -50.55 -50.1627 -49.8181 -49.4789 -48.8532 -48.5734 -48.2749 -48.1 -47.9566 -47.8304 -47.714 -47.6019 -47.4938 -47.3893 -47.2076 -47.0603 -46.9689 -46.8857 -46.8054 -46.7271 -46.6503 -46.5751 -46.5009 -46.4293 -46.3274 -46.2447 -46.2119 -46.1891 -46.1715 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Thu Jul 2 18:45:24 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
262 warnings in exp/tri5_ali/log/align_pass1.*.log
177 warnings in exp/tri5_ali/log/align_pass2.*.log
5 warnings in exp/tri5_ali/log/fmllr.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/203-lao/release-current/conversational/dev
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Lao_Babel203/dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/203-lao/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Lao_Babel203/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/203-lao/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Thu Jul 2 18:49:10 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Lao_Babel203/uem/db-dev-jhuseg-v7-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel203b-v3.1a_conv-dev/IARPA-babel203b-v3.1a_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Thu Jul 2 18:49:10 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Lao_Babel203/uem/db-dev-jhuseg-v7-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-dev-jhuseg-v7-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 0 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 131 files
filelist filelist.list contains 131 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Thu Jul 2 18:49:11 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_203_10188_20130220_225432_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 1.665), segments file: (15.11 15.74)
Warning: BABEL_OP1_203_10188_20130220_225432_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.665, 2.055), segments file: (15.11 15.74)
Warning: BABEL_OP1_203_10188_20130220_225432_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (2.055, 8.550), segments file: (15.11 15.74)
Warning: BABEL_OP1_203_10188_20130220_225432_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (8.550, 15.045), segments file: (15.11 15.74)
Warning: BABEL_OP1_203_10188_20130220_225432_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (15.045, 15.795), segments file: (15.11 15.74)
Warning: BABEL_OP1_203_10188_20130220_225432_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.915), segments file: (17.57 18.16)
Warning: BABEL_OP1_203_10188_20130220_225432_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.915, 1.285), segments file: (17.57 18.16)
Warning: BABEL_OP1_203_10188_20130220_225432_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.285, 12.375), segments file: (17.57 18.16)
Warning: BABEL_OP1_203_10188_20130220_225432_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (12.375, 13.085), segments file: (17.57 18.16)
Warning: BABEL_OP1_203_10188_20130220_225432_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (13.085, 17.495), segments file: (17.57 18.16)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Thu Jul 2 18:49:11 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 14331 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 14331 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Thu Jul 2 18:51:23 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Thu Jul 2 18:51:23 CDT 2015
---------------------------------------------------------------------
fstminimizeencoded 
fstdeterminizestar --use-log=true 
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstisstochastic data/lang/tmp/LG.fst 
0.000484306 -2.45969
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000484306 -2.45969
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fstdeterminizestar --use-log=true 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstminimizeencoded 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstrmepslocal 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.000883485 -2.45988
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Thu Jul 2 22:42:38 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Thu Jul 2 22:42:43 CDT 2015
lang = zulu, conf = conf/lang/206-zulu-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/206-zulu/release-current/conversational/training/ /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Zulu_Babel206/train.LimitedLP.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/206-zulu/release-current/conversational/training/ according to train.LimitedLP.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/206-zulu/release-current/conversational/dev/ /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Zulu_Babel206/dev.2hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/206-zulu/release-current/conversational/dev/ according to dev.2hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/206-zulu/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Zulu_Babel206/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/206-zulu/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Thu Jul 2 22:42:44 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/206-zulu/release-current/conversational/reference_materials/lexicon.sub-train.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ; k_> = ɠ ; 3 = e ; R = l ; o = ɔ ; b_< = b ; t_> = tʰ ;
local/prepare_lexicon.pl: Read 13674 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 18471 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 41 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 1 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 3 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Thu Jul 2 22:42:46 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 349 |' 'echo 13679 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 6 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 328 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 42 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 42 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 12 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 348 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 52 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 99 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Thu Jul 2 22:42:51 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 13678 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 124 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 10542 non-empty utterances from 124 files
local/prepare_acoustic_training_data.pl: Found 111 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 111 .sph files
local/prepare_acoustic_training_data.pl: Found 13 .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 13 .sph files
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 10542 lines each to text, utt2spk and segments
	Wrote 124 lines to wav.scp
	Wrote 120 lines to spk2utt
	Total # words = 64998 (including 2411 OOVs) + 17362 <silence>
	Amount of speech = 10.39 hours (including some due to <silence>)
	Average utterance length = 3.55 sec +/- 3.39 sec, and 6.17 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Thu Jul 2 22:42:53 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 20 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 1714 non-empty utterances from 20 files
local/prepare_acoustic_training_data.pl: Found 20 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 20 .sph files
ls: cannot access /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio/*.wav: No such file or directory
local/prepare_acoustic_training_data.pl NOTICE: No .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 1714 lines each to text, utt2spk and segments
	Wrote 20 lines to wav.scp
	Wrote 18 lines to spk2utt
	Amount of speech = 1.56 hours (including some due to <silence>)
	Average utterance length = 3.29 sec +/- 3.00 sec, and 5.47 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Thu Jul 2 22:42:53 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_206_14350_20121123_042710_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 6.232), segments file: (12.465 13.815)
Warning: BABEL_OP1_206_14350_20121123_042710_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (6.232, 12.465), segments file: (12.465 13.815)
Warning: BABEL_OP1_206_14350_20121123_042710_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (12.465, 13.815), segments file: (12.465 13.815)
Warning: BABEL_OP1_206_14350_20121123_042710_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (587.515, 590.040), segments file: (586.465 587.515)
Warning: BABEL_OP1_206_14350_20121123_042710_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 10.425), segments file: (15.405 16.155)
Warning: BABEL_OP1_206_14350_20121123_042710_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (10.425, 10.825), segments file: (15.405 16.155)
Warning: BABEL_OP1_206_14350_20121123_042710_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (10.825, 15.405), segments file: (15.405 16.155)
Warning: BABEL_OP1_206_14350_20121123_042710_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (15.405, 16.155), segments file: (15.405 16.155)
Warning: BABEL_OP1_206_14350_20121123_042710_outLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (590.105, 590.180), segments file: (572.765 590.105)
Warning: BABEL_OP1_206_15042_20130124_002208_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.485), segments file: (0.000 2.485)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Thu Jul 2 22:42:53 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 13680 lines, 13680 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 78868 words, 10542 sentences
train.txt contains 68326 words, 10542 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 11471 words, 1714 sentences
data/srilm/dev.txt contains 9757 words, 1714 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
warning: discount coeff 5 is out of range: 1.65065
warning: discount coeff 6 is out of range: 1.06067
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
warning: discount coeff 5 is out of range: 1.65065
warning: discount coeff 6 is out of range: 1.06067
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
warning: discount coeff 5 is out of range: 1.65065
warning: discount coeff 6 is out of range: 1.06067
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
warning: discount coeff 5 is out of range: 1.65065
warning: discount coeff 6 is out of range: 1.06067
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
warning: discount coeff 5 is out of range: 1.65065
warning: discount coeff 6 is out of range: 1.06067
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
warning: discount coeff 5 is out of range: 1.65065
warning: discount coeff 6 is out of range: 1.06067
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.14356
warning: discount coeff 5 is out of range: 1.65065
warning: discount coeff 6 is out of range: 1.06067
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -24499.9  ppl=  136.713  ppl1=  324.344
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -24538.7  ppl=  137.783  ppl1=  327.331
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -24543.7  ppl=  137.92   ppl1=  327.712
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -24568.9  ppl=  138.62   ppl1=  329.669
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -24845.2  ppl=  146.527  ppl1=  351.886
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -24850.2  ppl=  146.672  ppl1=  352.296
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -24875.4  ppl=  147.417  ppl1=  354.4
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -24962.9  ppl=  150.028  ppl1=  361.791
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -24972.6  ppl=  150.32   ppl1=  362.62
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25026.6  ppl=  151.96   ppl1=  367.274
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25030.9  ppl=  152.09   ppl1=  367.645
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25188.4  ppl=  156.975  ppl1=  381.566
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25193.3  ppl=  157.13   ppl1=  382.01
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25218.5  ppl=  157.928  ppl1=  384.291
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25253.3  ppl=  159.036  ppl1=  387.462
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25307.2  ppl=  160.764  ppl1=  392.416
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25311.5  ppl=  160.902  ppl1=  392.812
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25390.7  ppl=  163.482  ppl1=  400.227
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25574    ppl=  169.609  ppl1=  417.921
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25664.7  ppl=  172.725  ppl1=  426.961
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25669.3  ppl=  172.884  ppl1=  427.423
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  1714  sentences,  9757  words,  0  OOVs  0  zeroprobs,  logprob=  -25825.5  ppl=  178.39   ppl1=  443.472
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Thu Jul 2 22:43:03 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -2.66059
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Thu Jul 2 22:43:03 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept all 10542 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 10542 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Thu Jul 2 22:44:23 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 10542 to 5000
utils/subset_data_dir.sh: reducing #utt from 10542 to 10000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Thu Jul 2 22:44:24 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
908 warnings in exp/mono/log/acc.*.*.log
16036 warnings in exp/mono/log/align.*.*.log
110 warnings in exp/mono/log/update.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Thu Jul 2 22:55:55 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
2453 warnings in exp/tri1/log/align.*.*.log
1 warnings in exp/tri1/log/build_tree.log
1 warnings in exp/tri1/log/compile_questions.log
4 warnings in exp/tri1/log/update.*.log
8 warnings in exp/tri1/log/init_model.log
986 warnings in exp/tri1/log/acc.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Thu Jul 2 23:03:13 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri2/log/compile_questions.log
1 warnings in exp/tri2/log/build_tree.log
85 warnings in exp/tri2/log/init_model.log
71 warnings in exp/tri2/log/update.*.log
1956 warnings in exp/tri2/log/align.*.*.log
1037 warnings in exp/tri2/log/acc.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Thu Jul 2 23:23:55 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri3/log/build_tree.log
1925 warnings in exp/tri3/log/align.*.*.log
72 warnings in exp/tri3/log/update.*.log
68 warnings in exp/tri3/log/init_model.log
1 warnings in exp/tri3/log/compile_questions.log
1149 warnings in exp/tri3/log/acc.*.*.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Thu Jul 2 23:39:55 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
1 warnings in exp/tri4/log/build_tree.log
84 warnings in exp/tri4/log/update.*.log
1623 warnings in exp/tri4/log/align.*.*.log
77 warnings in exp/tri4/log/init_model.log
1 warnings in exp/tri4/log/compile_questions.log
32 warnings in exp/tri4/log/lda_acc.*.log
1008 warnings in exp/tri4/log/acc.*.*.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Thu Jul 2 23:47:20 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
74 warnings in exp/tri5/log/update.*.log
1 warnings in exp/tri5/log/compile_questions.log
1037 warnings in exp/tri5/log/acc.*.*.log
3 warnings in exp/tri5/log/est_alimdl.log
42 warnings in exp/tri5/log/init_model.log
1 warnings in exp/tri5/log/build_tree.log
144 warnings in exp/tri5/log/fmllr.*.*.log
1491 warnings in exp/tri5/log/align.*.*.log
steps/train_sat.sh: Likelihood evolution:
-53.9896 -53.6965 -53.532 -53.2545 -52.4512 -51.6964 -51.1503 -50.771 -50.4836 -49.9527 -49.6953 -49.3749 -49.1902 -49.054 -48.9322 -48.8198 -48.7096 -48.6013 -48.4984 -48.3132 -48.1636 -48.073 -47.9909 -47.9129 -47.836 -47.7591 -47.6853 -47.6143 -47.5457 -47.4409 -47.3545 -47.3192 -47.2954 -47.2784 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Thu Jul 2 23:55:44 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
26 warnings in exp/tri5_ali/log/fmllr.*.log
401 warnings in exp/tri5_ali/log/align_pass1.*.log
378 warnings in exp/tri5_ali/log/align_pass2.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/206-zulu/release-current/conversational/dev
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Zulu_Babel206/dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/206-zulu/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Zulu_Babel206/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/206-zulu/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Thu Jul 2 23:57:39 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Zulu_Babel206/uem/db-dev-jhuseg-v7-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel206b-v0.1e_conv-dev/IARPA-babel206b-v0.1e_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Thu Jul 2 23:57:39 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Zulu_Babel206/uem/db-dev-jhuseg-v7-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-dev-jhuseg-v7-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 0 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 141 files
filelist filelist.list contains 141 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Thu Jul 2 23:57:40 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_206_14350_20121123_042710_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 6.232), segments file: (13.34 13.78)
Warning: BABEL_OP1_206_14350_20121123_042710_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (6.232, 12.465), segments file: (13.34 13.78)
Warning: BABEL_OP1_206_14350_20121123_042710_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (12.465, 13.815), segments file: (13.34 13.78)
Warning: BABEL_OP1_206_14350_20121123_042710_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 10.425), segments file: (15.46 16.04)
Warning: BABEL_OP1_206_14350_20121123_042710_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (10.425, 10.825), segments file: (15.46 16.04)
Warning: BABEL_OP1_206_14350_20121123_042710_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (10.825, 15.405), segments file: (15.46 16.04)
Warning: BABEL_OP1_206_14350_20121123_042710_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (15.405, 16.155), segments file: (15.46 16.04)
Warning: BABEL_OP1_206_15042_20130124_002208_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 2.485), segments file: (1.89 2.96)
Warning: BABEL_OP1_206_15042_20130124_002208_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.375), segments file: (4.64 5.63)
Warning: BABEL_OP1_206_15042_20130124_002208_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.375, 1.785), segments file: (4.64 5.63)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Thu Jul 2 23:57:40 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 12382 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 12382 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Thu Jul 2 23:58:51 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Thu Jul 2 23:58:51 CDT 2015
---------------------------------------------------------------------
fstdeterminizestar --use-log=true 
fstminimizeencoded 
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstisstochastic data/lang/tmp/LG.fst 
0.000469727 -2.66021
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000469727 -2.66021
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstminimizeencoded 
fstdeterminizestar --use-log=true 
fstrmepslocal 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.693359 -2.66041
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Fri Jul 3 02:48:17 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Fri Jul 3 02:48:24 CDT 2015
lang = tamil, conf = conf/lang/204-tamil-limitedLP.official.conf
---------------------------------------------------------------------
Subsetting the TRAIN set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/204-tamil/release-current/conversational/training /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tamil_Babel204/train.LimitedLP.list ./data/raw_train_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/204-tamil/release-current/conversational/training according to train.LimitedLP.list
train_data_dir = /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data
---------------------------------------------------------------------
Subsetting the DEV2H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/204-tamil/release-current/conversational/dev/ /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tamil_Babel204/dev.2hr.list ./data/raw_dev2h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/204-tamil/release-current/conversational/dev/ according to dev.2hr.list
---------------------------------------------------------------------
Subsetting the DEV10H set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/204-tamil/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tamil_Babel204/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/204-tamil/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing lexicon in data/local on Fri Jul 3 02:48:27 CDT 2015
---------------------------------------------------------------------
local/make_lexicon_subset.sh /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/204-tamil/release-current/conversational/reference_materials/lexicon.sub-train.txt data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: data/local/filtered_lexicon.txt data/local
	Romanized forms of words expected in the dictionary
{ = æ ; {~ = æ̃ ; @ = ə ; a = a ; a~ = ã ; b = b ; b_h = bʱ ; d = d ; d` = ɖ ; d_h = dʱ ; d`_h = ɖʱ ; dZ = d͡ʒ ; dZ_h = d͡ʒʱ ; e = e ; e~ = ẽ ; <eps> = <eps> ; f = f ; g = ɡ ; g_h = ɡʱ ; h = h ; i = i ; i~ = ĩ ; j = j ; k = k ; k_h = kʰ ; l = l ; m = m ; n = n ; N = ŋ ; o = o ; o~ = õ ; O = ɔ ; O~ = ɔ̃ ; oi = oi ; <oov> = <oov> ; ou = ou ; ou~ = oũ ; p = p ; p_h = pʰ ; r = r ; r` = ɽ ; s = s ; S = ʃ ; SIL = SIL ; <sss> = <sss> ; t = t ; t` = ʈ ; t_h = tʰ ; t`_h = ʈʰ ; tS = t͡ʃ ; tS_h = t͡ʃʰ ; u = u ; u~ = ũ ; v = v ; <vns> = <vns> ; w = w ; z = z ; Z = ʒ ; 6 = ɐ ; 6j = ɐi ; 6w = ɐu ; 9: = œː ; 9y = œy ; a: = aː ; a:j = aːi ; a:w = aːu ; dz = d͡z ; E: = ɛː ; ej = ei ; gw = ɡu ; i: = iː ; iw = iu ; kw = ku ; O: = ɔː ; O:j = ɔːi ; ow = ou ; ts = t͡s ; u: = uː ; u:j = uːi ; y: = yː ; E = ɛ ; E~ = ɛ̃ ; j\ = ʝ ; j\_h = ʝʱ ; U = ʊ ; U~ = ʊ̃ ; x = x ; ? = ʔ ; 4 = ɾ ; A = ɑ ; C = ç ; G = ɣ ; n` = ɳ ; q = q ; s` = ʂ ; z` = ʐ ; 3 = ɜ ; aj = ai ; aw = au ; D = ð ; I = ɪ ; oj = oi ; T = θ ; uj = ui ; V = ʌ ; 1 = ɨ ; 1: = ɨː ; 2 = ø ; 2: = øː ; 5 = lˠ ; c = c ; e: = eː ; gj = ɡj ; o: = oː ; y = y ; a:I = aːɪ ; a:U = aːʊ ; aU = aʊ ; @U = əʊ ; aI = aɪ ; @I = əɪ ; EU = ɛʊ ; eU = eʊ ; iU = iʊ ; Oa: = ɔaː ; Oa = ɔa ; OE = ɔɛ ; OI = ɔɪ ; oI = oɪ ; @:I = əːɪ ; 1@ = ɨə ; ue = ue ; uI = uɪ ; 1I = ɨɪ ; u@: = uəː ; 1U = ɨʊ ; ui: = uiː ; @: = əː ; b_< = ɓ ; d_< = ɗ ; I: = ɪː ; J = ɲ ; J\ = ʄ ; r\ = ɹ ; ts` = t͡ɕ ; ts\ = t͡ɕ ; Hi = ɥ ; 7 = ɤ ; 7: = ɤː ; A: = ɑː ; Ao = ɑo ; i@ = iə ; M = ɯ ; M: = ɯː ; M@ = ɯə ; u@ = uə ; |\ = ǀ ; |\|\ = ǁ ; !\ = ǃ ; g_< = ɠ ; g_|\_t = g|\̤ ; g_|\|\_t = ɡǁ̤ ; g_!\_t = ɡǃ̤ ; |\_h = ǀʰ ; |\|\_h = ǁʰ ; !\_h = ǃʰ ; h\ = ɦ ; K = ɬ ; K\ = ɮ ; kx = kx ; k_> = kʼ ; p_> = pʼ ; t_> = tʼ ; tS_> = t͡ʃʼ ; ai = ai ; au = au ; l` = ɭ ; r\` = ɻ ; v\ = ʋ ;
local/prepare_lexicon.pl: Read 14265 entries from data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 18605 pronunciations to data/local/lexicon.txt
local/prepare_lexicon.pl: Wrote 34 (sets of) nonsilence phones to data/local/nonsilence_phones.txt
local/prepare_lexicon.pl: Wrote 4 silence phones to data/local/silence_phones.txt
local/prepare_lexicon.pl: Wrote 1 optional silence phones to data/local/optional_silence.txt
local/prepare_lexicon.pl: Found 0 unique individual tags in data/local/filtered_lexicon.txt
local/prepare_lexicon.pl: Wrote 2 extra questions (incl compound tags and sil) to data/local/extra_questions.txt
---------------------------------------------------------------------
Creating L.fst etc in data/lang on Fri Jul 3 02:48:29 CDT 2015
---------------------------------------------------------------------
Checking data/local/silence_phones.txt ...
--> reading data/local/silence_phones.txt
--> data/local/silence_phones.txt is OK

Checking data/local/optional_silence.txt ...
--> reading data/local/optional_silence.txt
--> data/local/optional_silence.txt is OK

Checking data/local/nonsilence_phones.txt ...
--> reading data/local/nonsilence_phones.txt
--> data/local/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/lexicon.txt
--> reading data/local/lexicon.txt
--> data/local/lexicon.txt is OK

Checking data/local/extra_questions.txt ...
--> reading data/local/extra_questions.txt
--> data/local/extra_questions.txt is OK
--> SUCCESS [validating dictionary directory data/local]

**Creating data/local/lexiconp.txt from data/local/lexicon.txt
fstaddselfloops 'echo 157 |' 'echo 14270 |' 
prepare_lang.sh: validating output directory
Checking data/lang/phones.txt ...
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> data/lang/words.txt has "#0"
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> summation property is OK

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> 4 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> 136 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> 20 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> 35 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> 35 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> 11 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> 156 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...
--> data/lang/topo's nonsilence section is OK
--> data/lang/topo's silence section is OK
--> data/lang/topo is OK

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word_boundary.int and disambig.int
--> generating a 32 word sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 100 word sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
---------------------------------------------------------------------
Preparing acoustic training lists in data/train on Fri Jul 3 02:48:41 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --vocab data/local/lexicon.txt --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data data/train
	Limiting transcriptions to words in data/local/lexicon.txt
	Mapping OOV tokens to "<unk>"
	if they remain OOV even after removing [-*~] from either end
Read 14269 unique words from data/local/lexicon.txt
local/prepare_acoustic_training_data.pl: Found 125 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 10721 non-empty utterances from 125 files
local/prepare_acoustic_training_data.pl: Found 119 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 119 .sph files
local/prepare_acoustic_training_data.pl: Found 6 .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_train_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 6 .sph files
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/train
local/prepare_acoustic_training_data.pl: Summary
	Wrote 10721 lines each to text, utt2spk and segments
	Wrote 125 lines to wav.scp
	Wrote 121 lines to spk2utt
	Total # words = 75426 (including 2496 OOVs) + 19660 <silence>
	Amount of speech = 11.77 hours (including some due to <silence>)
	Average utterance length = 3.95 sec +/- 3.57 sec, and 7.04 words
---------------------------------------------------------------------
Preparing dev2h data lists in data/dev2h on Fri Jul 3 02:48:44 CDT 2015
---------------------------------------------------------------------
local/prepare_acoustic_training_data.pl --fragmentMarkers -*~ /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data data/dev2h
local/prepare_acoustic_training_data.pl: Found 24 .txt files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/transcription
local/prepare_acoustic_training_data.pl: Recorded 1736 non-empty utterances from 24 files
local/prepare_acoustic_training_data.pl: Found 23 .sph files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 23 .sph files
local/prepare_acoustic_training_data.pl: Found 1 .wav files in /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev2h_data/audio
local/prepare_acoustic_training_data.pl: Recorded durations from headers of 1 .sph files
local/prepare_acoustic_training_data.pl: Writing 5 output files to data/dev2h
local/prepare_acoustic_training_data.pl: Summary
	Wrote 1736 lines each to text, utt2spk and segments
	Wrote 24 lines to wav.scp
	Wrote 20 lines to spk2utt
	Amount of speech = 1.91 hours (including some due to <silence>)
	Average utterance length = 3.97 sec +/- 3.44 sec, and 7.57 words
---------------------------------------------------------------------
Preparing dev2h stm files in data/dev2h on Fri Jul 3 02:48:44 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 11.775), segments file: (0.000 11.775)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (494.955, 506.945), segments file: (483.825 494.955)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (506.945, 518.925), segments file: (483.825 494.955)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (518.925, 519.345), segments file: (483.825 494.955)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (519.345, 519.400), segments file: (483.825 494.955)
Warning: BABEL_OP1_204_13189_20130613_161247_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 0.595), segments file: (4.175 5.755)
Warning: BABEL_OP1_204_13189_20130613_161247_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.595, 1.455), segments file: (4.175 5.755)
Warning: BABEL_OP1_204_13189_20130613_161247_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (1.455, 4.175), segments file: (4.175 5.755)
Warning: BABEL_OP1_204_13189_20130613_161247_outLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (4.175, 5.755), segments file: (4.175 5.755)
Warning: BABEL_OP1_204_13189_20130613_161247_outLine: the segment from the STM file starts after the last segment from the segments file ends
Warning: Additional info: STM: (485.155, 486.100), segments file: (483.565 485.155)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Training SRILM language models on Fri Jul 3 02:48:44 CDT 2015
---------------------------------------------------------------------
-------------------------------------
Building an SRILM language model     
-------------------------------------
Using words file: data/lang/words.txt
Using train text: data/train/text
Using dev text  : data/dev2h/text
vocab contains 14271 lines, 14271 words
Removed first word (uid) from every line of data/train/text
data/train/text contains 93209 words, 10721 sentences
train.txt contains 82488 words, 10721 sentences
Removed first word (uid) from every line of data/dev2h/text
data/dev2h/text contains 16045 words, 1736 sentences
data/srilm/dev.txt contains 14309 words, 1736 sentences
-------------------
Good-Turing 3grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
-------------------
Kneser-Ney 3grams
-------------------
-------------------
Good-Turing 4grams
-------------------
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
warning: discount coeff 6 is out of range: 1.45882
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
warning: discount coeff 6 is out of range: 1.45882
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
warning: discount coeff 6 is out of range: 1.45882
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
warning: discount coeff 6 is out of range: 1.45882
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
warning: discount coeff 6 is out of range: 1.45882
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
warning: discount coeff 6 is out of range: 1.45882
warning: discount coeff 1 is out of range: 0
warning: discount coeff 7 is out of range: 1.17452
warning: discount coeff 6 is out of range: 1.45882
-------------------
Kneser-Ney 4grams
-------------------
--------------------
Computing perplexity
--------------------
data/srilm/3gram.gt023.gz   file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -37854.3  ppl=  228.695  ppl1=  442.066
data/srilm/3gram.gt022.gz   file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -37881.4  ppl=  229.586  ppl1=  443.997
data/srilm/4gram.gt0223.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -37892.6  ppl=  229.955  ppl1=  444.798
data/srilm/4gram.gt0222.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -37893.3  ppl=  229.979  ppl1=  444.849
data/srilm/3gram.kn023.gz   file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38250.1  ppl=  242.062  ppl1=  471.139
data/srilm/3gram.kn022.gz   file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38256.4  ppl=  242.281  ppl1=  471.619
data/srilm/4gram.kn0222.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38283.1  ppl=  243.21   ppl1=  473.646
data/srilm/3gram.gt012.gz   file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38285.5  ppl=  243.296  ppl1=  473.835
data/srilm/4gram.kn0223.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38286    ppl=  243.313  ppl1=  473.872
data/srilm/4gram.gt0123.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38296.7  ppl=  243.688  ppl1=  474.689
data/srilm/4gram.gt0122.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38297.5  ppl=  243.713  ppl1=  474.744
data/srilm/3gram.kn012.gz   file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38641.9  ppl=  256.064  ppl1=  501.804
data/srilm/4gram.kn0122.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38668.6  ppl=  257.046  ppl1=  503.963
data/srilm/4gram.kn0123.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38671.6  ppl=  257.155  ppl1=  504.203
data/srilm/3gram.gt011.gz   file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38770.7  ppl=  260.839  ppl1=  512.309
data/srilm/4gram.gt0113.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38781.9  ppl=  261.258  ppl1=  513.233
data/srilm/4gram.gt0112.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38782.6  ppl=  261.285  ppl1=  513.292
data/srilm/4gram.gt0111.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -38912.8  ppl=  266.211  ppl1=  524.155
data/srilm/3gram.kn011.gz   file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -39100.2  ppl=  273.47   ppl1=  540.207
data/srilm/4gram.kn0112.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -39163.8  ppl=  275.975  ppl1=  545.76
data/srilm/4gram.kn0113.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -39176.5  ppl=  276.479  ppl1=  546.878
data/srilm/4gram.kn0111.gz  file  data/srilm/dev.txt:  1736  sentences,  14309  words,  0  OOVs  0  zeroprobs,  logprob=  -39286.1  ppl=  280.864  ppl1=  556.612
The perlexity scores report is stored in data/srilm/perplexities.txt 
---------------------------------------------------------------------
Creating G.fst on  Fri Jul 3 02:49:03 CDT 2015
---------------------------------------------------------------------
local/arpa2G.sh data/srilm/lm.gz data/lang data/lang
arpa2fst - 
Processing 1-grams
Processing 2-grams
Processing 3-grams
Connected 0 states without outgoing arcs.
fstisstochastic data/lang/G.fst 
0 -1.70839
---------------------------------------------------------------------
Starting plp feature extraction for data/train in plp on Fri Jul 3 02:49:05 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 16 data/train exp/make_plp_pitch/train plp
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for train
fix_data_dir.sh: kept all 10721 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
steps/compute_cmvn_stats.sh data/train exp/make_plp/train plp
Succeeded creating CMVN stats for train
fix_data_dir.sh: kept all 10721 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
---------------------------------------------------------------------
Subsetting monophone training data in data/train_sub[123] on Fri Jul 3 02:52:02 CDT 2015
---------------------------------------------------------------------
utils/subset_data_dir.sh: reducing #utt from 10721 to 5000
utils/subset_data_dir.sh: reducing #utt from 10721 to 10000
---------------------------------------------------------------------
Starting (small) monophone training in exp/mono on Fri Jul 3 02:52:03 CDT 2015
---------------------------------------------------------------------
steps/train_mono.sh --boost-silence 1.5 --nj 8 --cmd run.pl data/train_sub1 data/lang exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
9257 warnings in exp/mono/log/acc.*.*.log
34112 warnings in exp/mono/log/align.*.*.log
Done
---------------------------------------------------------------------
Starting (small) triphone training in exp/tri1 on Fri Jul 3 03:18:26 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 12 --cmd run.pl data/train_sub2 data/lang exp/mono exp/mono_ali_sub2
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub2 using model from exp/mono, putting alignments in exp/mono_ali_sub2
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 1000 10000 data/train_sub2 data/lang exp/mono_ali_sub2 exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/mono_ali_sub2 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri1/log/init_model.log
6587 warnings in exp/tri1/log/align.*.*.log
5 warnings in exp/tri1/log/update.*.log
1 warnings in exp/tri1/log/compile_questions.log
14252 warnings in exp/tri1/log/acc.*.*.log
1 warnings in exp/tri1/log/build_tree.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1
---------------------------------------------------------------------
Starting (medium) triphone training in exp/tri2 on Fri Jul 3 03:34:38 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 24 --cmd run.pl data/train_sub3 data/lang exp/tri1 exp/tri1_ali_sub3
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train_sub3 using model from exp/tri1, putting alignments in exp/tri1_ali_sub3
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train_sub3 data/lang exp/tri1_ali_sub3 exp/tri2
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri1_ali_sub3 to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
15353 warnings in exp/tri2/log/acc.*.*.log
1 warnings in exp/tri2/log/compile_questions.log
1 warnings in exp/tri2/log/build_tree.log
95 warnings in exp/tri2/log/update.*.log
5902 warnings in exp/tri2/log/align.*.*.log
85 warnings in exp/tri2/log/init_model.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2
---------------------------------------------------------------------
Starting (full) triphone training in exp/tri3 on Fri Jul 3 04:09:47 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri2 exp/tri2_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri2, putting alignments in exp/tri2_ali
steps/align_si.sh: done aligning data.
steps/train_deltas.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri2_ali exp/tri3
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
steps/train_deltas.sh: converting alignments from exp/tri2_ali to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
1 warnings in exp/tri3/log/compile_questions.log
5807 warnings in exp/tri3/log/align.*.*.log
97 warnings in exp/tri3/log/update.*.log
74 warnings in exp/tri3/log/init_model.log
15432 warnings in exp/tri3/log/acc.*.*.log
1 warnings in exp/tri3/log/build_tree.log
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri3
---------------------------------------------------------------------
Starting (lda_mllt) triphone training in exp/tri4 on Fri Jul 3 04:38:41 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri3 exp/tri3_ali
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri3, putting alignments in exp/tri3_ali
steps/align_si.sh: done aligning data.
steps/train_lda_mllt.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri3_ali exp/tri4
Accumulating LDA statistics.
rm: cannot remove 'exp/tri4/lda.*.acc': No such file or directory
Accumulating tree stats
Getting questions for tree clustering.
Building the tree
steps/train_lda_mllt.sh: Initializing the model
Converting alignments from exp/tri3_ali to use current tree
Compiling graphs of transcripts
Training pass 1
Training pass 2
Estimating MLLT
Training pass 3
Training pass 4
Estimating MLLT
Training pass 5
Training pass 6
Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
102 warnings in exp/tri4/log/init_model.log
450 warnings in exp/tri4/log/lda_acc.*.log
74 warnings in exp/tri4/log/update.*.log
5125 warnings in exp/tri4/log/align.*.*.log
1 warnings in exp/tri4/log/compile_questions.log
14060 warnings in exp/tri4/log/acc.*.*.log
1 warnings in exp/tri4/log/build_tree.log
Done training system with LDA+MLLT features in exp/tri4
---------------------------------------------------------------------
Starting (SAT) triphone training in exp/tri5 on Fri Jul 3 04:57:12 CDT 2015
---------------------------------------------------------------------
steps/align_si.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri4 exp/tri4_ali
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri4, putting alignments in exp/tri4_ali
steps/align_si.sh: done aligning data.
steps/train_sat.sh --boost-silence 1.5 --cmd run.pl 2500 36000 data/train data/lang exp/tri4_ali exp/tri5
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri4_ali
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
steps/train_sat.sh: Converting alignments from exp/tri4_ali to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
86 warnings in exp/tri5/log/update.*.log
1 warnings in exp/tri5/log/build_tree.log
3 warnings in exp/tri5/log/est_alimdl.log
12539 warnings in exp/tri5/log/acc.*.*.log
4724 warnings in exp/tri5/log/align.*.*.log
1 warnings in exp/tri5/log/compile_questions.log
1951 warnings in exp/tri5/log/fmllr.*.*.log
43 warnings in exp/tri5/log/init_model.log
steps/train_sat.sh: Likelihood evolution:
-53.1238 -52.9444 -52.7218 -52.3898 -51.4386 -50.6397 -50.195 -49.8536 -49.5657 -49.0577 -48.7973 -48.405 -48.1893 -48.0512 -47.9282 -47.811 -47.7029 -47.6015 -47.5046 -47.3444 -47.2096 -47.1275 -47.0527 -46.9825 -46.9142 -46.8456 -46.7765 -46.709 -46.6452 -46.5559 -46.4767 -46.4447 -46.4227 -46.4063 
Done
---------------------------------------------------------------------
Starting exp/tri5_ali on Fri Jul 3 05:18:20 CDT 2015
---------------------------------------------------------------------
steps/align_fmllr.sh --boost-silence 1.5 --nj 16 --cmd run.pl data/train data/lang exp/tri5 exp/tri5_ali
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri5/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
1328 warnings in exp/tri5_ali/log/align_pass2.*.log
1430 warnings in exp/tri5_ali/log/align_pass1.*.log
395 warnings in exp/tri5_ali/log/fmllr.*.log
Exiting after stage TRI5, as requested. 
Everything went fine. Done
run-4-test.sh --skip-kws true --tri5-only true --dir dev10h.uem
dataset_segments = uem
dataset_dir = data/dev10h.uem
dataset_id = dev10h.uem
dataset_type = dev10h
dataset_kind = supervised
my_data_dir = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/204-tamil/release-current/conversational/dev
my_data_list = /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tamil_Babel204/dev.list
my_nj = 32
---------------------------------------------------------------------
Subsetting the dev10h set
---------------------------------------------------------------------
local/make_corpus_subset.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/204-tamil/release-current/conversational/dev /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tamil_Babel204/dev.list ./data/raw_dev10h_data
Making subsets from /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/204-tamil/release-current/conversational/dev according to dev.list
---------------------------------------------------------------------
Preparing supervised data files in data/dev10h.uem on Fri Jul 3 05:23:44 CDT 2015
---------------------------------------------------------------------
my_data_dir=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data
my_data_list=/ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data/filelist.list
my_nj=32
my_data_cmudb=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tamil_Babel204/uem/db-dev-jhuseg-v8-utt.dat
my_stm_file=/ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/scoring/IndusDB/IARPA-babel204b-v1.1b_conv-dev/IARPA-babel204b-v1.1b_conv-dev.stm
---------------------------------------------------------------------
Preparing dev10h data lists in data/dev10h.uem on Fri Jul 3 05:23:44 CDT 2015
---------------------------------------------------------------------
local/cmu_uem2kaldi_dir.sh /ws/ifp-48_1/hasegawa/amitdas/corpus/babel/data/splits/Tamil_Babel204/uem/db-dev-jhuseg-v8-utt.dat /ws/ifp-48_1/hasegawa/amitdas/work/kaldi/egs_061115/babel/s5c/data/raw_dev10h_data data/dev10h.uem
Converting db-dev-jhuseg-v8-utt.dat to kaldi directory data/dev10h.uem 
Because of using filelist, 0 files omitted
Creating the data/dev10h.uem/utt2spk file
Creating the data/dev10h.uem/spk2utt file
Creating the data/dev10h.uem/wav.scp file
wav.scp contains 125 files
filelist filelist.list contains 125 files
Creating the data/dev10h.uem/text file
Creating the data/dev10h.uem/reco2file_and_channel file
Everything done
---------------------------------------------------------------------
Preparing dev10h stm files in data/dev10h.uem on Fri Jul 3 05:23:45 CDT 2015
---------------------------------------------------------------------
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (0.000, 11.775), segments file: (170.90 182.86)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (11.775, 34.235), segments file: (170.90 182.86)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (11.775, 34.235), segments file: (170.90 182.86)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (34.235, 43.405), segments file: (170.90 182.86)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (43.405, 55.375), segments file: (170.90 182.86)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (55.375, 67.175), segments file: (170.90 182.86)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (67.175, 78.515), segments file: (170.90 182.86)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (78.515, 90.355), segments file: (170.90 182.86)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (90.355, 102.085), segments file: (170.90 182.86)
Warning: BABEL_OP1_204_13189_20130613_161247_inLine: The segment from the STM file start before the first segment from the segments file
Warning: Additional info: STM: (102.085, 111.435), segments file: (170.90 182.86)
Warning: Maximum number of warning reached, not warning anymore...
---------------------------------------------------------------------
Preparing supervised parametrization files in data/dev10h.uem on Fri Jul 3 05:23:45 CDT 2015
---------------------------------------------------------------------
steps/make_plp_pitch.sh --cmd run.pl --nj 32 data/dev10h.uem exp/make_plp/dev10h.uem plp
The channel should be marked as A or B, not 1! You should change it ASAP! 
utils/validate_data_dir.sh: Successfully validated data-directory data/dev10h.uem
steps/make_plp_pitch.sh [info]: segments file exists: using that.
Succeeded creating PLP & Pitch features for dev10h.uem
fix_data_dir.sh: kept all 13176 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
steps/compute_cmvn_stats.sh data/dev10h.uem exp/make_plp/dev10h.uem plp
Succeeded creating CMVN stats for dev10h.uem
fix_data_dir.sh: kept all 13176 utterances.
fix_data_dir.sh: old files are kept in data/dev10h.uem/.backup
---------------------------------------------------------------------
Preparing kws data files in data/dev10h.uem on Fri Jul 3 05:26:06 CDT 2015
---------------------------------------------------------------------
---------------------------------------------------------------------
Spawning decoding with SAT models  on Fri Jul 3 05:26:06 CDT 2015
---------------------------------------------------------------------
fsttablecompose data/lang/L_disambig.fst data/lang/G.fst 
fstminimizeencoded 
fstdeterminizestar --use-log=true 
WARNING (fsttablecompose:main():fsttablecompose.cc:131) The second FST is not ilabel sorted.
fstisstochastic data/lang/tmp/LG.fst 
0.000481507 -1.70809
[info]: LG not stochastic.
fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang/phones/disambig.int --write-disambig-syms=data/lang/tmp/disambig_ilabels_3_1.int data/lang/tmp/ilabels_3_1 
fstisstochastic data/lang/tmp/CLG_3_1.fst 
0.000481507 -1.70809
[info]: CLG not stochastic.
make-h-transducer --disambig-syms-out=exp/tri5/graph/disambig_tid.int --transition-scale=1.0 data/lang/tmp/ilabels_3_1 exp/tri5/tree exp/tri5/final.mdl 
fstdeterminizestar --use-log=true 
fsttablecompose exp/tri5/graph/Ha.fst data/lang/tmp/CLG_3_1.fst 
fstminimizeencoded 
fstrmsymbols exp/tri5/graph/disambig_tid.int 
fstrmepslocal 
fstisstochastic exp/tri5/graph/HCLGa.fst 
0.000843048 -1.70834
HCLGa is not stochastic
add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri5/final.mdl 
steps/decode_fmllr_extra.sh --skip-scoring true --beam 10 --lattice-beam 4 --nj 32 --cmd run.pl --num-threads 6 --parallel-opts -pe smp 6 -l mem_free=4G,ram_free=4.0G exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem
steps/decode.sh --acwt 0.083333 --nj 32 --cmd run.pl --beam 10.0 --model exp/tri5/final.alimdl --max-active 2000 --num-threads 6 --skip-scoring true exp/tri5/graph data/dev10h.uem exp/tri5/decode_dev10h.uem.si
decode.sh: feature type is lda
steps/decode_fmllr_extra.sh: feature type is lda
steps/decode_fmllr_extra.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr_extra.sh: doing first adapted lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr_extra.sh: doing final lattice generation phase
steps/decode_fmllr_extra.sh: estimating fMLLR transforms a third time.
steps/decode_fmllr_extra.sh: doing a final pass of acoustic rescoring.
--tri5-only is true. So exiting.
local/score.sh --cmd run.pl data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
local/lattice_to_ctm.sh --cmd run.pl --word-ins-penalty 0.5 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Lattice2CTM finished on  Fri Jul 3 09:07:32 CDT 2015
local/score_stm.sh --cmd run.pl --cer 0 --min-lmwt 8 --max-lmwt 12 data/dev10h.uem exp/tri5/graph exp/tri5/decode_dev10h.uem
Finished scoring on Fri Jul 3 09:07:59 CDT 2015
